{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cba0864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omote/cluster_project/iam2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import wandb\n",
    "import glob\n",
    "import os\n",
    "import regex as re\n",
    "from torchvision.ops import box_iou\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer,util\n",
    "import sys\n",
    "sys.path.append(\"/home/omote/cluster_project/iam2/eval\")\n",
    "from eval_utils.custom_oc_cost import get_cmap,get_ot_cost,DetectedInstance\n",
    "import math\n",
    "from copy import deepcopy\n",
    "def load_json(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Data loaded from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def sort_list_of_dicts(data, key, reverse=False):\n",
    "    \"\"\"\n",
    "    Sort a list of dictionaries by the specified key.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of dictionaries to sort.\n",
    "        key (str): Key to sort by.\n",
    "        reverse (bool): Sort in descending order if True, ascending if False.\n",
    "\n",
    "    Returns:\n",
    "        list: Sorted list of dictionaries.\n",
    "    \"\"\"\n",
    "    return sorted(data, key=lambda x: x[key], reverse=reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1701cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter((row) => row[\"ce_iou_over_0.5_count\"] != null and row[\"prop_iou_over_0.5_count\"] != null)\n",
    "# runs.summary[\"result_table\"].table.rows[0].filter((row) => row[\"ce_iou_over_0.5_count\"] < row[\"prop_iou_over_0.5_count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "513cb8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bbox_from_text(ans):\n",
    "    pattern = re.compile(r'\\[(((0|1)\\.(\\d){3}\\,\\s*){3}((0|1)\\.(\\d){3}))\\]')\n",
    "    match_list = pattern.findall(ans)\n",
    "\n",
    "    if len(match_list) > 0:\n",
    "        answer = [list(map(float,match[0].split(\",\"))) for match in match_list]\n",
    "    else:\n",
    "        answer = \"FAILED\"\n",
    "    return answer\n",
    "\n",
    "def calculate_iou(gt_bbox_list, pred_bbox_list):\n",
    "    # print(gt_bbox_list)\n",
    "    # print(pred_bbox_list)\n",
    "    iou_matrix = box_iou(torch.tensor(gt_bbox_list).float(), torch.tensor(pred_bbox_list).float())\n",
    "    iou_matrix = torch.nan_to_num(iou_matrix, nan=0.0)  # NaNを0に置き換える\n",
    "    iou_argsort_matrix = torch.argsort(iou_matrix.flatten(),descending=True).argsort().reshape(iou_matrix.shape)#iouが大きい順にソートしたインデックスを取得\n",
    "    # print(iou_argsort_matrix)\n",
    "    # print(\"-\" * 50)\n",
    "    # print(iou_matrix)\n",
    "    pred_index_list =  torch.full((len(pred_bbox_list),), False, dtype=torch.bool)\n",
    "    gt_index_list = torch.full((len(gt_bbox_list),), False, dtype=torch.bool)\n",
    "\n",
    "    short_index_list = pred_index_list if len(pred_bbox_list) < len(gt_bbox_list) else gt_index_list\n",
    "    iou_info_list = []\n",
    "\n",
    "    # print(iou_matrix.numel())\n",
    "    for i in range(iou_matrix.numel()):\n",
    "        max_iou_index = torch.where(iou_argsort_matrix == i)\n",
    "        if not gt_index_list[max_iou_index[0]] and not pred_index_list[max_iou_index[1]]:\n",
    "            iou_info_list.append( {\n",
    "                \"gt_index\": max_iou_index[0].item(),\n",
    "                \"pred_index\": max_iou_index[1].item(),\n",
    "                \"iou_value\": iou_matrix[max_iou_index].item()\n",
    "            })\n",
    "            gt_index_list[max_iou_index[0]] = True\n",
    "            pred_index_list[max_iou_index[1]] = True\n",
    "            # print(f\"index {i} - gt_index: {max_iou_index[0].item()}, pred_index: {max_iou_index[1].item()}, iou_value: {iou_matrix[max_iou_index].item()}\")\n",
    "        \n",
    "        if torch.all(short_index_list):\n",
    "            break\n",
    "        \n",
    "    assert len(iou_info_list) == min(len(gt_bbox_list), len(pred_bbox_list)), f\"Length mismatch: {len(iou_info_list)} != {min(len(gt_bbox_list), len(pred_bbox_list))}\"\n",
    "    # print(iou_info_list)\n",
    "    # for iou_info in iou_info_list:\n",
    "    #     if math.isnan(iou_info[\"iou_value\"]):\n",
    "    #         print(f\"IOU value is NaN for gt index {iou_info['gt_index']} and pred index {iou_info['pred_index']}\")\n",
    "    #         print(iou_matrix[iou_info['gt_index'], iou_info['pred_index']])\n",
    "    #         print(iou_matrix[iou_info['gt_index'], iou_info['pred_index']].item())\n",
    "    #         print(iou_info[\"iou_value\"])\n",
    "    #         print(iou_matrix)\n",
    "    \n",
    "    return iou_info_list,iou_matrix,iou_argsort_matrix,pred_index_list, gt_index_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806aae99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_bbox_valid(bbox, box_w_h=[1, 1], min_bbox_size=1e-6):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    if x1 < 0 or y1 < 0 or x2 < 0 or y2 < 0:\n",
    "        return False\n",
    "    if x1 > box_w_h[0] or y1 > box_w_h[1] or x2 > box_w_h[0] or y2 > box_w_h[1]:\n",
    "        return False\n",
    "    if x1 >= x2 or y1 >= y2:\n",
    "        return False\n",
    "    bbox_area = (x2 - x1) * (y2 - y1)\n",
    "    if bbox_area < min_bbox_size:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def parse_bbox_and_labels(processor,detokenizer_output: str):\n",
    "    # pattern = r\"((<loc\\d{4}>){4})[^;<]+|((<loc\\d{4}>){4})$\"\n",
    "    # matches = re.findall(pattern, detokenizer_output)\n",
    "    # print(\"matches\", matches)\n",
    "    pattern = r\"(((<loc\\d{4}>){4})([^;<]+))\"\n",
    "    matches = re.findall(pattern, detokenizer_output)\n",
    "    if len(matches) > 0 and matches[0][-1].strip() != \"\":\n",
    "        label_list = []\n",
    "        bbox_list = []\n",
    "        for m in matches:\n",
    "            y1, x1, y2, x2 = [int(x)/1024.0 for x in re.findall(r'\\d+', m[1])]\n",
    "            if check_bbox_valid([x1, y1, x2, y2], box_w_h=[1, 1], min_bbox_size=1e-6):\n",
    "                bbox_list.append([x1, y1, x2, y2])\n",
    "                label_list.append(m[-1].strip())\n",
    "        return bbox_list, label_list\n",
    "\n",
    "    pattern = r\"([^<]+)((<loc\\d{4}>){4})\"\n",
    "    matches = re.findall(pattern, detokenizer_output)\n",
    "    if len(matches) > 0:\n",
    "        label_pattern = r\"^<image>detect\\s([^<]+)<loc\\d{4}>\"\n",
    "        match = re.findall(label_pattern, detokenizer_output)\n",
    "        if len(match) > 0 and match[0].strip() != \"\":\n",
    "            label = match[0].strip()\n",
    "            bbox_list = []\n",
    "            for m in matches:\n",
    "                y1, x1, y2, x2 = [int(x)/1024.0 for x in re.findall(r'\\d+', m[1])]\n",
    "                if check_bbox_valid([x1, y1, x2, y2], box_w_h=[1, 1], min_bbox_size=1e-6):\n",
    "                    bbox_list.append([x1, y1, x2, y2])\n",
    "            label_list = [label] * len(bbox_list)\n",
    "            return bbox_list, label_list\n",
    "    \n",
    "    return [], []\n",
    "\n",
    "\n",
    "def add_bbox_to_wandb_image(wandb_image, entities,cat_2_id_dict=None,add_number=True):\n",
    "    # load raw input photo\n",
    "    # person_label_num = 20\n",
    "    # other_label_num = 20\n",
    "    # display_ids = {}\n",
    "    # for i in range(person_label_num):\n",
    "    #     display_ids.update({f\"person{i+1}\": i})\n",
    "    # class_id_to_label = {int(v): k for k, v in display_ids.items()}\n",
    "    # for num, i in enumerate(\n",
    "    #     range(person_label_num, person_label_num + other_label_num)\n",
    "    # ):\n",
    "    #     class_id_to_label.update({i: f\"p_other{num+1}\"})\n",
    "    assert type(wandb_image) == wandb.Image\n",
    "    name_list = []\n",
    "    bbox_list = []\n",
    "    for entity in entities:\n",
    "        bbox_list.extend(entity[-1])\n",
    "        name_list.extend([entity[0]]*len(entity[-1]))\n",
    "    # print(entities)\n",
    "    # print(bbox_list)\n",
    "    # print(name_list)\n",
    "    assert len(name_list) == len(bbox_list)\n",
    "        \n",
    "    if cat_2_id_dict == None:\n",
    "        tmp_class_num = 200\n",
    "        id_2_cat_dict = {i:f\"cat_{i}\" for i in range(tmp_class_num)}\n",
    "        # cat_2_id_dict = {}\n",
    "        # # print(name_list)\n",
    "        # for i,name in enumerate(name_list):\n",
    "        #     # # print(name,i)\n",
    "        #     # # print(type(name))\n",
    "        #     # print({name:i})\n",
    "        #     cat_2_id_dict.update({name:i})\n",
    "    else:\n",
    "        cat_2_id_dict = deepcopy(cat_2_id_dict)\n",
    "        cat_2_id_dict.update({\"unknown\":max(cat_2_id_dict.values())+1})\n",
    "    \n",
    "        id_2_cat_dict = {v:k for k,v in cat_2_id_dict.items()}\n",
    "        \n",
    "    # import pdb;pdb.set_trace()\n",
    "    # print(cat_2_id_dict)\n",
    "    appear_num_dict = {k:-1 for k in cat_2_id_dict.keys()}\n",
    "    class_id = -1\n",
    "    if len(name_list) > 0:\n",
    "        all_boxes = []\n",
    "        # plot each bounding box for this image\n",
    "        for name, bbox in zip(name_list, bbox_list):\n",
    "            if cat_2_id_dict is not None and name in cat_2_id_dict:\n",
    "                class_id = cat_2_id_dict[name]\n",
    "                if add_number:\n",
    "                    \n",
    "                    appear_num_dict[name] += 1\n",
    "                    name = f\"{name}_{appear_num_dict[name]}\"\n",
    "            elif cat_2_id_dict is not None:\n",
    "                class_id = cat_2_id_dict[\"unknown\"]\n",
    "                if add_number:\n",
    "                    appear_num_dict[name] += 1\n",
    "                    name = f\"{name}_{appear_num_dict[name]}\"\n",
    "            else:\n",
    "                class_id +=1\n",
    "                \n",
    "            box_data = {\n",
    "                \"position\": {\n",
    "                    \"minX\": bbox[0],\n",
    "                    \"maxX\": bbox[2],\n",
    "                    \"minY\": bbox[1],\n",
    "                    \"maxY\": bbox[3],\n",
    "                },\n",
    "                \"class_id\": class_id,  # display_ids[b_name] if b_name in display_ids else 0,\n",
    "                # optionally caption each box with its class and score\n",
    "                \"box_caption\": name,\n",
    "                # \"domain\" : \"null\",#\"pixel\",\n",
    "                # \"scores\" : { }\n",
    "            }\n",
    "            all_boxes.append(box_data)\n",
    "\n",
    "        # log to wandb: raw image, predictions, and dictionary of class labels for each class id\n",
    "        box_image = wandb.Image(\n",
    "            wandb_image,\n",
    "            boxes={\n",
    "                \"predictions\": {\n",
    "                    \"box_data\": all_boxes,\n",
    "                    \"class_labels\": id_2_cat_dict,\n",
    "                }\n",
    "            },\n",
    "        )\n",
    "            # box_image = wandb.Image(wandb_image, boxes = {\"predictions\": {\"box_data\": all_boxes}})\n",
    "    else:\n",
    "        box_image = wandb_image\n",
    "    return box_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6f6d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56e14bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oc_cost(pred_instance_list,tgt_instance_list, alpha=0.5,beta=0.6):\n",
    "    cmap_func = lambda x, y: get_cmap(x, y, alpha=alpha, beta=beta,label_or_sim=\"label\")\n",
    "    otc = get_ot_cost(pred_instance_list, tgt_instance_list, cmap_func)\n",
    "    return otc\n",
    "\n",
    "def similariry_score(str1, str2, model: SentenceTransformer):\n",
    "    # compute embedding for both lists\n",
    "    embedding_1 = model.encode(str1, show_progress_bar=False)\n",
    "    embedding_2 = model.encode(str2, show_progress_bar=False)\n",
    "    score = util.pytorch_cos_sim(embedding_1, embedding_2).item()\n",
    "    \n",
    "    #スコア丸め込み\n",
    "    # score = min(score, 1.0)\n",
    "    # score = max(score, 0.0)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def create_get_most_similar_category_func(category_list, sentence_transformer_model_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    similarity_model = SentenceTransformer(sentence_transformer_model_path).to(device)\n",
    "    category_embeddings = similarity_model.encode(category_list, show_progress_bar=False, convert_to_tensor=True)\n",
    "    def get_most_similar_category(category_name):\n",
    "        category_embedding = similarity_model.encode(category_name, show_progress_bar=False, convert_to_tensor=True)\n",
    "        scores = util.pytorch_cos_sim(category_embedding, category_embeddings).squeeze(0)\n",
    "        most_similar_index = torch.argmax(scores).item()\n",
    "        return category_list[most_similar_index], scores[most_similar_index].item(), scores\n",
    "    return get_most_similar_category\n",
    "\n",
    "def get_per_image_class_result_and_oc_cost(all_gt_annotations, all_pred_annotations, cat_name2id, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate per-image and per-category results and calculate occlusion cost.\n",
    "\n",
    "    Args:\n",
    "        all_gt_annotations (dict): Ground truth annotations.\n",
    "        all_pred_annotations (dict): Predicted annotations.\n",
    "        cat_name2id (dict): Category name to ID mapping.\n",
    "        iou_threshold (float): IOU threshold for true positives.\n",
    "\n",
    "    Returns:\n",
    "        dict: Per-image results and occlusion costs.\n",
    "    \"\"\"\n",
    "    per_image_result_dict = {}\n",
    "    break_index = 10\n",
    "    oc_cost_list = []\n",
    "    for index, gt_per_image_annotation_list in tqdm(all_gt_annotations.items()):\n",
    "        pred_per_image_annotation_list = all_pred_annotations.get(index, [])\n",
    "        \n",
    "        # 画像ごとの評価\n",
    "        pred_instance_list = [DetectedInstance(\n",
    "            label=ann[\"category_id\"],\n",
    "            x1=ann[\"bbox_xyxy\"][0],\n",
    "            y1=ann[\"bbox_xyxy\"][1],\n",
    "            x2=ann[\"bbox_xyxy\"][2],\n",
    "            y2=ann[\"bbox_xyxy\"][3]) for ann in pred_per_image_annotation_list]\n",
    "        tgt_instance_list = [DetectedInstance(\n",
    "            label=ann[\"category_id\"],\n",
    "            x1=ann[\"bbox_xyxy\"][0],\n",
    "            y1=ann[\"bbox_xyxy\"][1],\n",
    "            x2=ann[\"bbox_xyxy\"][2],\n",
    "            y2=ann[\"bbox_xyxy\"][3]) for ann in gt_per_image_annotation_list]\n",
    "        \n",
    "        oc_cost_value = oc_cost(pred_instance_list, tgt_instance_list, alpha=0.5, beta=0.6)\n",
    "        oc_cost_list.append(oc_cost_value)\n",
    "        \n",
    "        #画像ごと・カテゴリごとの評価準備\n",
    "        gt_per_category_dict = {}\n",
    "        pred_per_category_dict = {}\n",
    "        per_category_result_dict = {\"ann_id\": gt_per_image_annotation_list[0][\"ann_id\"]}\n",
    "        \n",
    "        for category_id in cat_name2id.values():\n",
    "            gt_per_category_dict[category_id] = None\n",
    "            pred_per_category_dict[category_id] = None\n",
    "            per_category_result_dict[category_id] = None\n",
    "            \n",
    "        for annotation in gt_per_image_annotation_list:\n",
    "            if gt_per_category_dict[annotation[\"category_id\"]] is None:\n",
    "                gt_per_category_dict[annotation[\"category_id\"]] = []\n",
    "            gt_per_category_dict[annotation[\"category_id\"]].append(annotation)\n",
    "        \n",
    "        for annotation in pred_per_image_annotation_list:\n",
    "            if pred_per_category_dict[annotation[\"category_id\"]] is None:\n",
    "                pred_per_category_dict[annotation[\"category_id\"]] = []\n",
    "            pred_per_category_dict[annotation[\"category_id\"]].append(annotation)\n",
    "        \n",
    "        \n",
    "        for category_id, gt_annotations in gt_per_category_dict.items():\n",
    "            pred_annotations = pred_per_category_dict[category_id]\n",
    "            if gt_annotations is None and  pred_annotations is None:\n",
    "                continue\n",
    "            \n",
    "            per_category_result = {\n",
    "                \"iou_list\": [],\n",
    "                \"pred_iou_list\": [],\n",
    "                \"tp_num\": 0,\n",
    "                \"fp_num\": 0,\n",
    "                \"fn_num\": 0,\n",
    "            }\n",
    "            if gt_annotations is None and pred_per_category_dict[category_id] is not None:\n",
    "                per_category_result[\"fp_num\"] = len(pred_per_category_dict[category_id])\n",
    "                pred_bbox_list = [ann[\"bbox_xyxy\"] for ann in pred_annotations]\n",
    "                per_category_result[\"pred_bbox_list\"] = pred_bbox_list\n",
    "                per_category_result[\"iou_info_list\"] = []\n",
    "            elif gt_annotations is not None:\n",
    "                if pred_per_category_dict[category_id] is None:\n",
    "                    per_category_result[\"fn_num\"] = len(gt_annotations)\n",
    "                    per_category_result[\"iou_list\"] = [0.0] * len(gt_annotations)\n",
    "                    per_category_result[\"pred_bbox_list\"] = []\n",
    "                    per_category_result[\"iou_info_list\"] = []\n",
    "\n",
    "                else: \n",
    "                    gt_bbox_list = [ann[\"bbox_xyxy\"] for ann in gt_annotations]\n",
    "                    pred_bbox_list = [ann[\"bbox_xyxy\"] for ann in pred_annotations]\n",
    "                    iou_info_list,iou_matrix,iou_argsort_matrix,pred_index_list, gt_index_listt = calculate_iou(gt_bbox_list, pred_bbox_list)\n",
    "                    assert ((len(gt_bbox_list) < len(pred_bbox_list) and len(iou_info_list) == len(gt_bbox_list)) or (len(gt_bbox_list) >= len(pred_bbox_list) and len(iou_info_list) == len(pred_bbox_list))), f\"Length mismatch in category {category_id}, index {index}: len(iou_info_list)={len(iou_info_list)}, len(gt_bbox_list)={len(gt_bbox_list)}, len(pred_bbox_list)={len(pred_bbox_list)}\"\n",
    "                    # if not((len(gt_bbox_list) < len(pred_bbox_list) and len(iou_info_list) == len(gt_bbox_list)) or \\\n",
    "                    #     (len(gt_bbox_list) >= len(pred_bbox_list) and len(iou_info_list) == len(pred_bbox_list))):\n",
    "                        # print(f\"index: {index}, category_id: {category_id}, len(iou_info_list): {len(iou_info_list)}, len(gt_bbox_list): {len(gt_bbox_list)}, len(pred_bbox_list): {len(pred_bbox_list)}\")\n",
    "                        # print(f\"pred_bbox_list: {pred_bbox_list}\")\n",
    "                        # print(f\"gt_bbox_list: {gt_bbox_list}\")\n",
    "                        # print(f\"iou_info_list: {iou_info_list}\")\n",
    "                        # print(f\"iou_matrix: {iou_matrix}\")\n",
    "                        # print(f\"iou_argsort_matrix: {iou_argsort_matrix}\")\n",
    "                        # print(f\"pred_index_list: {pred_index_list}\")\n",
    "                        # print(f\"gt_index_list: {gt_index_listt}\")\n",
    "                        # raise ValueError(\"IOU information length mismatch\")\n",
    "                    iou_list = [info[\"iou_value\"] for info in iou_info_list]\n",
    "                    per_category_result[\"pred_iou_list\"] = deepcopy(iou_list)\n",
    "                    for iou in iou_list:\n",
    "                        assert not math.isnan(iou), f\"IOU value is NaN in category {category_id}, index {index}\"\n",
    "                    if len(iou_list) < len(gt_bbox_list):\n",
    "                        iou_list += [0.0] * (len(gt_bbox_list) - len(iou_list))\n",
    "                    \n",
    "                    \n",
    "                    # for iou in iou_list:\n",
    "                    #     assert not math.isnan(iou), f\"IOU value is NaN in category {category_id}, index {index}\"\n",
    "                    per_category_result[\"iou_list\"] = iou_list\n",
    "                    tp_num = sum(1 for iou in iou_list if iou >= iou_threshold)\n",
    "                    per_category_result[\"tp_num\"] = tp_num\n",
    "                    per_category_result[\"fp_num\"] = len(pred_bbox_list) - tp_num\n",
    "                    per_category_result[\"fn_num\"] = len(gt_bbox_list) - tp_num\n",
    "                    per_category_result[\"iou_info_list\"] = iou_info_list\n",
    "                    per_category_result[\"pred_bbox_list\"] = pred_bbox_list\n",
    "                    # if index == 9 and category_id == 84:\n",
    "                    #     visualize_bbox(\n",
    "                    #         os.path.join(image_folder_root, images[index][\"file_name\"]),\n",
    "                    #         pred_bbox_list,\n",
    "                    #         [ann[\"category_name\"] for ann in pred_annotations],\n",
    "                    #         bbox_is_relative=True,\n",
    "                    #         with_id=True\n",
    "                    #     )\n",
    "                    #     print(per_category_result)\n",
    "                    #     print(pred_bbox_list == gt_bbox_list)\n",
    "                    #     print(len(pred_bbox_list), len(gt_bbox_list))\n",
    "                    #     print(iou_info_list)\n",
    "            \n",
    "            per_category_result_dict[category_id] = per_category_result\n",
    "        \n",
    "        per_image_result_dict[index] = per_category_result_dict\n",
    "        # if index >= break_index:\n",
    "        #     break\n",
    "    return per_image_result_dict, oc_cost_list \n",
    "\n",
    "def create_annotations_for_coco(conversation_dataset,categories,get_bbox_func,processor,delete_region_failure=False,unknown_to_similar=False,sentence_transformer_model_path=None):\n",
    "    if unknown_to_similar and not delete_region_failure:\n",
    "        raise ValueError(\"unknown_to_similar is True but delete_region_failure is False. This combination is not supported.\")\n",
    "    elif unknown_to_similar and delete_region_failure:\n",
    "        get_most_similar_category = create_get_most_similar_category_func(\n",
    "            list(categories.keys()),\n",
    "            sentence_transformer_model_path\n",
    "        )\n",
    "    else:\n",
    "        get_most_similar_category = None\n",
    "\n",
    "    ann_id_converastaion_dict = {}\n",
    "    for i, conversation in enumerate(conversation_dataset):\n",
    "        if conversation[\"ann_id\"] not in ann_id_converastaion_dict:\n",
    "            ann_id_converastaion_dict[conversation[\"ann_id\"]] = []\n",
    "        ann_id_converastaion_dict[conversation[\"ann_id\"]].append(i)\n",
    "        \n",
    "    return_annotations = {}\n",
    "    \n",
    "    ann_keys_list = ann_id_converastaion_dict.keys()\n",
    "\n",
    "    region_failure_count = 0\n",
    "    region_failure_delim_count = 0\n",
    "    name_failure_count = 0\n",
    "    name_failure_delim_count = 0\n",
    "    name_match_count = 0\n",
    "    name_match_delim_count = 0\n",
    "\n",
    "    id_index = 0\n",
    "    for i, ann_key in enumerate(tqdm(ann_keys_list)):\n",
    "        for conversation in ann_id_converastaion_dict[ann_key]:\n",
    "            text = \"\"\n",
    "            for conv in conversation_dataset[conversation][\"conversations\"]:\n",
    "                text += conv[\"value\"]\n",
    "\n",
    "            ori_bbox_list,name_list = get_bbox_func(processor,text)\n",
    "            for name,bbox in zip(name_list,ori_bbox_list):\n",
    "                bbox_list = [bbox]\n",
    "                # import pdb;pdb.set_trace()\n",
    "                if \"<patch_index\" in name and delete_region_failure:\n",
    "                    #raise ValueError(f\"Unexpected patch index in name: {name}\")\n",
    "                    region_failure_count += 1\n",
    "                    region_failure_delim_count += len(bbox_list)\n",
    "                    continue\n",
    "                elif name not in categories.keys():    \n",
    "                    name_failure_count += 1\n",
    "                    name_failure_delim_count += len(bbox_list)\n",
    "                    if get_most_similar_category is not None:\n",
    "                        name, score, _ = get_most_similar_category(name)\n",
    "                else:\n",
    "                    name_match_count += 1\n",
    "                    name_match_delim_count += len(bbox_list)\n",
    "                    \n",
    "                for bbox in bbox_list:\n",
    "                    annotation = {\n",
    "                        \"id\": id_index,\n",
    "                        \"image_id\": i ,\n",
    "                        \"category_id\": categories[name] if name in categories else categories[\"unknown\"],\n",
    "                        \"bbox\": [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]],  # [x, y, width, height]\n",
    "                        \"area\": (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]),\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"score\": 1.0,  # Assuming all annotations are perfect for dummy data\n",
    "                        \"category_name\": name,\n",
    "                        \"bbox_xyxy\": bbox,  # [x1, y1, x2, y2]\n",
    "                        \"is_unknown\": 1 if name not in categories else 0,\n",
    "                        \"ann_id\": ann_key\n",
    "                    }\n",
    "                    \n",
    "                    if i not in return_annotations:\n",
    "                        return_annotations[i] = []\n",
    "                    return_annotations[i].append(annotation)\n",
    "                    id_index += 1\n",
    "\n",
    "    return_num_dict = {\n",
    "        \"region_failure_count\": region_failure_count,\n",
    "        \"region_failure_delim_count\": region_failure_delim_count,\n",
    "        \"name_failure_count\": name_failure_count,\n",
    "        \"name_failure_delim_count\": name_failure_delim_count,\n",
    "        \"name_match_count\": name_match_count,\n",
    "        \"name_match_delim_count\": name_match_delim_count\n",
    "    }\n",
    "    return return_annotations, return_num_dict\n",
    "\n",
    "def get_pascal_voc_category():\n",
    "    cat_id2name = {\n",
    "    0: \"aeroplane\",\n",
    "    1: \"bicycle\",\n",
    "    2: \"bird\",\n",
    "    3: \"boat\",\n",
    "    4: \"bottle\",\n",
    "    5: \"bus\",\n",
    "    6: \"car\",\n",
    "    7: \"cat\",\n",
    "    8: \"chair\",\n",
    "    9: \"cow\",\n",
    "    10: \"diningtable\",\n",
    "    11: \"dog\",\n",
    "    12: \"horse\",\n",
    "    13: \"motorbike\",\n",
    "    14: \"person\",\n",
    "    15: \"pottedplant\",\n",
    "    16: \"sheep\",\n",
    "    17: \"sofa\",\n",
    "    18: \"train\",\n",
    "    19: \"tvmonitor\",\n",
    "    }\n",
    "    \n",
    "    cat_name2id = {v:k for k, v in cat_id2name.items()}\n",
    "    return cat_name2id, cat_id2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1bf3913",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correct_table_data(correct_data,wandb_name_to_image,category_name_to_id):\n",
    "    correct_dict = {}\n",
    "\n",
    "    all_object_name_list = list(category_name_to_id.keys())\n",
    "    \n",
    "    for i in tqdm(range(len(correct_data)), desc=\"Processing correct data\"):\n",
    "        ann_id = correct_data[i][\"ann_id\"]\n",
    "        if  ann_id not in correct_dict:\n",
    "            bbox_num = 0\n",
    "            all_entities_dict = {k: [] for k in all_object_name_list}\n",
    "            for entity in correct_data[i][\"gt_entities_quantized_normalized\"]:\n",
    "                name = entity[0]\n",
    "                all_entities_dict[name].extend(entity[-1])\n",
    "                bbox_num += len(entity[-1])\n",
    "                \n",
    "            image_name = os.path.basename(correct_data[i][\"image\"])\n",
    "            correct_dict[ann_id] = {\n",
    "                \"ann_id\": ann_id,\n",
    "                \"id_list\": [correct_data[i][\"id\"]],\n",
    "                \"image_name\": image_name,\n",
    "                \"gt_entities\": all_entities_dict,\n",
    "                \"input\": [correct_data[i][\"conversations\"][0][\"value\"]],\n",
    "                \"gt_bbox_num\": bbox_num,\n",
    "                \"gt_output\": [correct_data[i][\"conversations\"][1][\"value\"]]\n",
    "            }\n",
    "        else:\n",
    "            current_entities_dict = correct_dict[ann_id][\"gt_entities\"]\n",
    "            current_bbox_num = correct_dict[ann_id][\"gt_bbox_num\"]\n",
    "            \n",
    "            for entity in correct_data[i][\"gt_entities_quantized_normalized\"]:\n",
    "                name = entity[0]\n",
    "                all_entities_dict[name].extend(entity[-1])\n",
    "                current_bbox_num += len(entity[-1])\n",
    "                \n",
    "            correct_dict[ann_id][\"id_list\"].append(correct_data[i][\"id\"])\n",
    "            correct_dict[ann_id][\"gt_entities\"] = current_entities_dict\n",
    "            correct_dict[ann_id][\"gt_bbox_num\"] = current_bbox_num\n",
    "            correct_dict[ann_id][\"input\"].append(correct_data[i][\"conversations\"][0][\"value\"])\n",
    "            correct_dict[ann_id][\"gt_output\"].append(correct_data[i][\"conversations\"][1][\"value\"])\n",
    "            \n",
    "    for ann_id, v in correct_dict.items():\n",
    "        gt_entities_list = []\n",
    "        current_entities_dict = v[\"gt_entities\"]\n",
    "        for name in all_object_name_list:\n",
    "            if len(current_entities_dict[name]) == 0:\n",
    "                del current_entities_dict[name]\n",
    "            else:\n",
    "                gt_entities_list.append([name, current_entities_dict[name]])\n",
    "        v[\"gt_entities\"] = gt_entities_list\n",
    "        v[\"gt_image\"] = add_bbox_to_wandb_image(wandb_name_to_image[v[\"image_name\"]], v[\"gt_entities\"], category_name_to_id)\n",
    "        \n",
    "    return sort_list_of_dicts(correct_dict.values(),key=\"ann_id\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3330e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generated_table_data(correct_data, generated_data, unique_key,wandb_name_to_image,category_name2id,category_id2name):\n",
    "    all_gt_annotations, all_gt_num_dict = create_annotations_for_coco(correct_data, category_name2id,parse_bbox_and_labels, None)\n",
    "    all_pred_annotations, all_pred_num_dict = create_annotations_for_coco(generated_data, category_name2id, parse_bbox_and_labels,None,\n",
    "            delete_region_failure=True, unknown_to_similar=True, sentence_transformer_model_path=\"/data_ssd/huggingface_model_weights/sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    per_image_result_dict, oc_cost_list = get_per_image_class_result_and_oc_cost(all_gt_annotations, all_pred_annotations, category_name2id, iou_threshold=0.5)\n",
    "\n",
    "    \n",
    "    \n",
    "    eval_dict = {}\n",
    "    for data in generated_data:\n",
    "        ann_id = data[\"ann_id\"]\n",
    "        if ann_id not in eval_dict:\n",
    "            image_name = os.path.basename(data[\"image\"])\n",
    "            eval_dict[ann_id] = {\n",
    "                \"ann_id\": ann_id,\n",
    "                \"image_name\": image_name,\n",
    "                f\"{unique_key}_pred_output\": []\n",
    "            }\n",
    "        pred_output = data[\"conversations\"][1][\"value\"]\n",
    "        eval_dict[ann_id][f\"{unique_key}_pred_output\"].append(pred_output)\n",
    "\n",
    "    for per_image_result, oc_cost_value in tqdm(zip(per_image_result_dict.values(), oc_cost_list)):\n",
    "        ann_id = per_image_result[\"ann_id\"]\n",
    "        del per_image_result[\"ann_id\"]\n",
    "        pred_bbox_num = 0\n",
    "        pred_entities = []\n",
    "        iou_info_list = []\n",
    "        iou_over_0_5_count = 0\n",
    "        for category_id, result in per_image_result.items():\n",
    "\n",
    "            if result is None:\n",
    "                continue\n",
    "            category_name = category_id2name[category_id]\n",
    "            pred_bbox_num += len(result[\"pred_bbox_list\"])\n",
    "            pred_entities.append([category_name, result[\"pred_bbox_list\"]])\n",
    "            iou_info_list.append([category_name, result[\"iou_info_list\"]])\n",
    "            iou_over_0_5_count += result[\"tp_num\"]\n",
    "        eval_item = eval_dict[ann_id]\n",
    "        eval_item[f\"{unique_key}_pred_bbox_num\"] = pred_bbox_num\n",
    "        \n",
    "        eval_item[f\"{unique_key}_iou_info_list\"] = str(iou_info_list)\n",
    "        eval_item[f\"{unique_key}_iou_over_0_5_count\"] = iou_over_0_5_count\n",
    "        eval_item[f\"{unique_key}_oc_cost\"] = float(oc_cost_value)\n",
    "        eval_item[f\"{unique_key}_pred_image\"] = add_bbox_to_wandb_image(\n",
    "            wandb_name_to_image[eval_item[\"image_name\"]], pred_entities, category_name2id\n",
    "        )\n",
    "        eval_item[f\"{unique_key}_pred_entities\"] = str(pred_entities)\n",
    "    return sort_list_of_dicts(eval_dict.values(),key=\"ann_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d77a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_path = \"/data_ssd/PASCAL-VOC/paligemma_actual_detection/test_pascal-voc_actual_detection_for_paligemma_sort_size_cat_size.json\"\n",
    "# compare_dict = {\n",
    "#     \"ce\": \"/data_ssd/USER_DATA/omote/iam-llms-finetune/experiment_output/paligemma_pascalvoc-multi-class-448px/448px_size_aligned_train-vision-proj-llm_cross-entropy_2025-10-17T18_07_18\",\n",
    "#     \"prop\": \"/data_ssd/USER_DATA/omote/iam-llms-finetune/experiment_output/paligemma_pascalvoc-multi-class-448px/448px_size_aligned_train-vision-proj-llm_cedfl_excepted_split_ce_2025-10-18T00_33_59\",\n",
    "# }\n",
    "compare_dict = {\n",
    "    \"ce\": \"/home/omote/omote-data-ssd/iam-llms-finetune/experiment_output/paligemma_pascalvoc-actual-detection-448px/448px_size_aligned_train-vision-proj-llm_cross-entropy_2025-10-20T22_29_37\",\n",
    "    \"prop\": \"/home/omote/omote-data-ssd/iam-llms-finetune/experiment_output/paligemma_pascalvoc-actual-detection-448px/448px_size_aligned_train-vision-proj-llm_cedfl_excepted2_split_ce_2025-10-21T11_38_04\",\n",
    "}\n",
    "\n",
    "\n",
    "eval_json_name = \"test_pascal-voc_actual_detection_for_paligemma_sort_size_cat_size\"\n",
    "\n",
    "artifact_entity = \"katlab-gifu/dataset/pascal_voc_test:v0\"\n",
    "\n",
    "ENTITY = \"katlab-gifu\"\n",
    "PROJECT = \"vis_test\"\n",
    "NAME=\"pascalvoc_actual_detection_comparison_448px_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60ad0405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33momote-hideaki-s8\u001b[0m (\u001b[33mkatlab-gifu\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/omote/cluster_project/iam2/dataset/pacal-voc2012/wandb/run-20251029_065614-tq956u28</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/katlab-gifu/vis_test/runs/tq956u28' target=\"_blank\">pascalvoc_actual_detection_comparison_448px_1</a></strong> to <a href='https://wandb.ai/katlab-gifu/vis_test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/katlab-gifu/vis_test' target=\"_blank\">https://wandb.ai/katlab-gifu/vis_test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/katlab-gifu/vis_test/runs/tq956u28' target=\"_blank\">https://wandb.ai/katlab-gifu/vis_test/runs/tq956u28</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(entity=ENTITY, project=PROJECT, name=NAME)\n",
    "img_art = run.use_artifact(artifact_entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c204a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact pascal_voc_test:v0, 1454.43MB. 4953 files... \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   4953 of 4953 files downloaded.  \n",
      "Done. 0:0:14.4 (101.0MB/s)\n"
     ]
    }
   ],
   "source": [
    "wandb_dataset = img_art.get(\"pascal_voc_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24fd397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_name_to_image = {data_row[0]: data_row[1] for data_row in wandb_dataset.data}\n",
    "wandb_image_names = set(wandb_name_to_image.keys())\n",
    "assert len(wandb_image_names) == len(wandb_name_to_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2685a7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wandb_name_to_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fd902be",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_compare_dict = {}\n",
    "for k,v in compare_dict.items():\n",
    "    file_list = glob.glob(os.path.join(v,\"**\",eval_json_name,\"**\",\"eval_output.json\"),recursive=True)\n",
    "    assert len(file_list) == 1\n",
    "    new_compare_dict[k] = file_list[0]\n",
    "compare_dict = new_compare_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e76299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name2id,category_id2name = get_pascal_voc_category()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bb05bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_data = load_json(gt_path)\n",
    "correct_data = sort_list_of_dicts(correct_data, \"id\")\n",
    "# all_gt_annotations, all_gt_num_dict = create_annotations_for_coco(correct_data, category_name2id,parse_bbox_and_labels, None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfae3b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing correct data: 100%|██████████| 4952/4952 [00:00<00:00, 16510.36it/s]\n"
     ]
    }
   ],
   "source": [
    "correct_data_list = get_correct_table_data(correct_data,wandb_name_to_image,category_name2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76f33606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ann_id': '000001', 'id_list': ['000001'], 'image_name': '000001.jpg', 'gt_entities': [['dog', [[0.13294232649071358, 0.4780058651026393, 0.5493646138807429, 0.739980449657869]]], ['person', [[0.019550342130987292, 0.022482893450635387, 0.9941348973607038, 0.9941348973607038]]]], 'input': ['<image>Detect objects in this image from the following categories: [aeroplane ; bicycle ; bird ; boat ; bottle ; bus ; car ; cat ; chair ; cow ; diningtable ; dog ; horse ; motorbike ; person ; pottedplant ; sheep ; sofa ; train ; tvmonitor]. List detected categories only.'], 'gt_bbox_num': 2, 'gt_output': ['<loc0023><loc0020><loc1017><loc1017> person ; <loc0489><loc0136><loc0757><loc0562> dog'], 'gt_image': <wandb.sdk.data_types.image.Image object at 0x1469f0ceb410>}\n"
     ]
    }
   ],
   "source": [
    "print(correct_data_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74d6f46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4952/4952 [00:00<00:00, 17750.21it/s]\n",
      "100%|██████████| 4952/4952 [00:00<00:00, 7553.51it/s]\n",
      "100%|██████████| 4952/4952 [00:03<00:00, 1245.68it/s]\n",
      "4952it [00:28, 170.79it/s]\n",
      "100%|██████████| 4952/4952 [00:00<00:00, 7688.59it/s]\n",
      "100%|██████████| 4952/4952 [00:00<00:00, 15292.95it/s]\n",
      "100%|██████████| 4952/4952 [00:03<00:00, 1245.00it/s]\n",
      "4952it [00:29, 170.42it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "wandb_columns = [\"ann_id\",\"id_list\",\"image_name\",\"gt_image\",\"input\",\"gt_output\",\"gt_bbox_num\",\"gt_entities\"]\n",
    "tmp_table_data = []\n",
    "for item in correct_data_list:\n",
    "    row_data = [str(item[k]) if not (type(item[k]) ==  wandb.Image or type(item[k]) ==  int or type(item[k]) ==  float) else item[k] for k in wandb_columns ]\n",
    "    tmp_table_data.append(row_data)\n",
    "\n",
    "for unique_key, generated_path in compare_dict.items():\n",
    "    generated_data = load_json(generated_path)\n",
    "    assert len(correct_data) == len(generated_data), \"Length of correct and generated data does not match.\"\n",
    "    generated_data = sort_list_of_dicts(generated_data, \"id\")\n",
    "    generated_data_list = get_generated_table_data(correct_data, generated_data, unique_key, wandb_name_to_image, category_name2id, category_id2name)\n",
    "    \n",
    "    unique_columns = [\n",
    "        f\"{unique_key}_pred_image\",\n",
    "        f\"{unique_key}_pred_output\",\n",
    "        f\"{unique_key}_pred_bbox_num\",\n",
    "        f\"{unique_key}_iou_info_list\",\n",
    "        f\"{unique_key}_iou_over_0_5_count\",\n",
    "        f\"{unique_key}_oc_cost\",\n",
    "        f\"{unique_key}_pred_entities\"\n",
    "    ]\n",
    "    \n",
    "    for i in range(len(tmp_table_data)):\n",
    "        assert tmp_table_data[i][0] == generated_data_list[i][\"ann_id\"], f\"Ann ID mismatch at index {i}.\"\n",
    "        for col in unique_columns:\n",
    "            if type(generated_data_list[i][col]) ==  wandb.Image or type(generated_data_list[i][col]) ==  int or type(generated_data_list[i][col]) ==  float:\n",
    "                tmp_table_data[i].append(generated_data_list[i][col])\n",
    "            else:\n",
    "                tmp_table_data[i].append(str(generated_data_list[i][col]))\n",
    "    wandb_columns.extend(unique_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5073c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(tmp_table_data):\n",
    "    # assert len(d) == len(wandb_columns), f\"Data length mismatch at index {i}: {len(d)} != {len(wandb_columns)}\"\n",
    "    for col,d in zip(wandb_columns,d):\n",
    "    #     print(col,type(d),d )\n",
    "    # break\n",
    "        if d is None or None in (d if type(d) == list else [d]):\n",
    "            print(f\"None value found in column {col} at row {i}\")\n",
    "            print(f\"Type of d: {type(d)}\")\n",
    "            print(f\"Value of d: {d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343507d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a34530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(tmp_table_data):\n",
    "    assert len(d) == len(wandb_columns), f\"Data length mismatch at index {i}: {len(d)} != {len(wandb_columns)}\"\n",
    "    # for col,d in zip(wandb_columns,d):\n",
    "    #     print(col,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d758c3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ann_id <class 'str'> 000001\n",
      "id_list <class 'str'> ['000001']\n",
      "image_name <class 'str'> 000001.jpg\n",
      "gt_image <class 'wandb.sdk.data_types.image.Image'> <wandb.sdk.data_types.image.Image object at 0x1469f0ceb410>\n",
      "input <class 'str'> ['<image>Detect objects in this image from the following categories: [aeroplane ; bicycle ; bird ; boat ; bottle ; bus ; car ; cat ; chair ; cow ; diningtable ; dog ; horse ; motorbike ; person ; pottedplant ; sheep ; sofa ; train ; tvmonitor]. List detected categories only.']\n",
      "gt_output <class 'str'> ['<loc0023><loc0020><loc1017><loc1017> person ; <loc0489><loc0136><loc0757><loc0562> dog']\n",
      "gt_bbox_num <class 'int'> 2\n",
      "gt_entities <class 'str'> [['dog', [[0.13294232649071358, 0.4780058651026393, 0.5493646138807429, 0.739980449657869]]], ['person', [[0.019550342130987292, 0.022482893450635387, 0.9941348973607038, 0.9941348973607038]]]]\n",
      "ce_pred_image <class 'wandb.sdk.data_types.image.Image'> <wandb.sdk.data_types.image.Image object at 0x146990cfae40>\n",
      "ce_pred_output <class 'str'> ['<loc0031><loc0000><loc1021><loc1020> person ; <loc0499><loc0147><loc0732><loc0565> dog']\n",
      "ce_pred_bbox_num <class 'int'> 2\n",
      "ce_iou_info_list <class 'str'> [['dog', [{'gt_index': 0, 'pred_index': 0, 'iou_value': 0.8417996168136597}]], ['person', [{'gt_index': 0, 'pred_index': 0, 'iou_value': 0.9658726453781128}]]]\n",
      "ce_iou_over_0_5_count <class 'int'> 2\n",
      "ce_oc_cost <class 'float'> 0.024177730083465576\n",
      "ce_pred_entities <class 'str'> [['dog', [[0.1435546875, 0.4873046875, 0.5517578125, 0.71484375]]], ['person', [[0.0, 0.0302734375, 0.99609375, 0.9970703125]]]]\n",
      "prop_pred_image <class 'wandb.sdk.data_types.image.Image'> <wandb.sdk.data_types.image.Image object at 0x14689f7339b0>\n",
      "prop_pred_output <class 'str'> ['<loc0030><loc0000><loc1021><loc1020> person ; <loc0495><loc0145><loc0732><loc0565> dog']\n",
      "prop_pred_bbox_num <class 'int'> 2\n",
      "prop_iou_info_list <class 'str'> [['dog', [{'gt_index': 0, 'pred_index': 0, 'iou_value': 0.8602877855300903}]], ['person', [{'gt_index': 0, 'pred_index': 0, 'iou_value': 0.9668303728103638}]]]\n",
      "prop_iou_over_0_5_count <class 'int'> 2\n",
      "prop_oc_cost <class 'float'> 0.02173110842704773\n",
      "prop_pred_entities <class 'str'> [['dog', [[0.1416015625, 0.4833984375, 0.5517578125, 0.71484375]]], ['person', [[0.0, 0.029296875, 0.99609375, 0.9970703125]]]]\n"
     ]
    }
   ],
   "source": [
    "for col, d in zip(wandb_columns, tmp_table_data[0]):\n",
    "    print(col, type(d), d )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "217fb5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">pascalvoc_actual_detection_comparison_448px_1</strong> at: <a href='https://wandb.ai/katlab-gifu/vis_test/runs/tq956u28' target=\"_blank\">https://wandb.ai/katlab-gifu/vis_test/runs/tq956u28</a><br> View project at: <a href='https://wandb.ai/katlab-gifu/vis_test' target=\"_blank\">https://wandb.ai/katlab-gifu/vis_test</a><br>Synced 5 W&B file(s), 1 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251029_065614-tq956u28/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result_table = wandb.Table(columns=wandb_columns, data=tmp_table_data)\n",
    "wandb.log({\"result_table\": result_table})\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7b71fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5302c11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604fae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f77e89c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba25d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tuple_list = []\n",
    "for c_item, g_item in zip(correct_data, generated_data):\n",
    "    assert c_item[\"id\"] == g_item[\"id\"], f\"ID mismatch: {c_item['id']} != {g_item['id']}\"\n",
    "    pred_input = generated_data[\"conversations\"][0][\"value\"]\n",
    "    pred_output = generated_data[i][\"conversations\"][1][\"value\"]\n",
    "    pred_bbox_list, pred_label_list = paligemma_get_bbox(pred_output)\n",
    "    pred_bbox_num = len(pred_bbox_list)\n",
    "    \n",
    "    pred_entities = [pred_input, pred_bbox_list]\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7115c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_data_tuple_list = []\n",
    "for item in correct_data:\n",
    "    id = item[\"id\"]\n",
    "    ann_id = item[\"ann_id\"]\n",
    "    image_name = os.path.basename(item[\"image\"])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf78ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76001217",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_columns = [\"ann_id\",\"id_list\",\"image_name\",\"gt_image\",\"input\",\"gt_output\",\"gt_bbox_num\",\"gt_entities\"]\n",
    "\n",
    "for key, path in compare_dict.items():\n",
    "    wandb_columns.append(f\"{key}_pred_image\")\n",
    "    wandb_columns.append(f\"{key}_pred_output\")\n",
    "    wandb_columns.append(f\"{key}_pred_bbox_num\")\n",
    "    wandb_columns.append(f\"{key}_pred_entities\")\n",
    "    wandb_columns.append(f\"{key}_iou_info_list\")\n",
    "    wandb_columns.append(f\"{key}_iou_over_0.5_count\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c28e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9c2407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef06bb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c7978d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f695403",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=ENTITY, project=PROJECT, id=RUN_ID, resume=\"must\")\n",
    "img_art = run.use_artifact(artifact_entity)\n",
    "img_dir = Path(img_art.download())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = wandb.Table(columns=[\"image_id\", \"image\", \"n_boxes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6290118d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc17430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

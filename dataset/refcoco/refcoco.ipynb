{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49ab6c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53309ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_id():\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "def make_conversation(id,image_path,question,answer,image_folder_root=None):\n",
    "    if image_folder_root is not None:\n",
    "        image_path = os.path.join(image_folder_root, image_path)\n",
    "    return_data =   {\n",
    "        \"id\": id,\n",
    "        \"image\": image_path,\n",
    "        \"conversations\": [\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": f\"<image>\\n{question}\"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": answer\n",
    "        },\n",
    "        ]\n",
    "    }\n",
    "    return return_data\n",
    "\n",
    "\n",
    "def make_question(caption):\n",
    "    return  f\"Provide the bounding box coordinate of the region this sentence describes: {caption}\"\n",
    "\n",
    "def bbox_absolute_to_relative(absolute_bbox, image_width_height):\n",
    "    width, height = image_width_height\n",
    "    x1 = absolute_bbox[0] / width\n",
    "    y1 = absolute_bbox[1] / height\n",
    "    x2 = absolute_bbox[2] / width\n",
    "    y2 = absolute_bbox[3] / height\n",
    "    relative_bbox = [x1, y1, x2, y2]\n",
    "    return relative_bbox\n",
    "\n",
    "def make_answer(bbox, image_width_height):\n",
    "    relative_bbox = bbox_absolute_to_relative(bbox, image_width_height)\n",
    "    relative_bbox = [f\"{coord:.3f}\" for coord in relative_bbox]\n",
    "    \n",
    "    return f\"[{relative_bbox[0]},{relative_bbox[1]},{relative_bbox[2]},{relative_bbox[3]}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fff610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_split = \"testB\"\n",
    "\n",
    "dataset_root_dir = \"/data_ssd/huggingface_dataset\"\n",
    "\n",
    "cache_dir = \"/data_ssd/huggingface_cache\"\n",
    "save_json_path = f\"/data_ssd/refcoco/refcoco-{data_split}_llava-onevision.json\"\n",
    "\n",
    "dataset_id = os.path.join(dataset_root_dir,\"jxu124/refcoco\")\n",
    "\n",
    "dataset = load_dataset(dataset_id, cache_dir=cache_dir, split=data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dee72514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sent_ids': [71, 72, 73], 'file_name': 'COCO_train2014_000000581563_3.jpg', 'ann_id': 1345868, 'ref_id': 25, 'image_id': 581563, 'split': 'testB', 'sentences': [{'raw': 'lower left corner darkness', 'sent': 'lower left corner darkness', 'sent_id': 71, 'tokens': ['lower', 'left', 'corner', 'darkness']}, {'raw': 'bpttom left dark', 'sent': 'bpttom left dark', 'sent_id': 72, 'tokens': ['bpttom', 'left', 'dark']}, {'raw': 'black van in front of cab', 'sent': 'black van in front of cab', 'sent_id': 73, 'tokens': ['black', 'van', 'in', 'front', 'of', 'cab']}], 'category_id': 3, 'raw_anns': '{\"segmentation\": [[59.15, 500.0, 0.48, 500.0, 0.0, 375.26, 96.66, 373.89, 104.85, 380.71, 117.13, 384.81, 127.36, 395.04, 134.86, 403.91, 137.59, 410.04, 112.41, 433.82, 108.59, 435.48, 105.11, 441.62, 103.45, 447.26, 95.99, 447.09, 62.98, 457.54]], \"area\": 12101.243650000002, \"iscrowd\": 0, \"image_id\": 581563, \"bbox\": [0.0, 373.89, 137.59, 126.11], \"category_id\": 3, \"id\": 1345868}', 'raw_image_info': '{\"license\": 3, \"file_name\": \"COCO_train2014_000000581563.jpg\", \"coco_url\": \"http://mscoco.org/images/581563\", \"height\": 500, \"width\": 333, \"date_captured\": \"2013-11-16 17:51:55\", \"flickr_url\": \"http://farm1.staticflickr.com/125/337273203_7eb35b845b_z.jpg\", \"id\": 581563}', 'raw_sentences': '[{\"tokens\": [\"lower\", \"left\", \"corner\", \"darkness\"], \"raw\": \"lower left corner darkness\", \"sent_id\": 71, \"sent\": \"lower left corner darkness\"}, {\"tokens\": [\"bpttom\", \"left\", \"dark\"], \"raw\": \"bpttom left dark\", \"sent_id\": 72, \"sent\": \"bpttom left dark\"}, {\"tokens\": [\"black\", \"van\", \"in\", \"front\", \"of\", \"cab\"], \"raw\": \"black van in front of cab\", \"sent_id\": 73, \"sent\": \"black van in front of cab\"}]', 'image_path': 'coco/train2014/COCO_train2014_000000581563.jpg', 'bbox': [0.0, 373.89, 137.59, 500.0], 'captions': ['lower left corner darkness', 'bpttom left dark', 'black van in front of cab'], 'global_image_id': 'coco.581563', 'anns_id': 'refcoco.1345868'}\n",
      "sent_ids: [71, 72, 73]\n",
      "file_name: COCO_train2014_000000581563_3.jpg\n",
      "ann_id: 1345868\n",
      "ref_id: 25\n",
      "image_id: 581563\n",
      "split: testB\n",
      "sentences: [{'raw': 'lower left corner darkness', 'sent': 'lower left corner darkness', 'sent_id': 71, 'tokens': ['lower', 'left', 'corner', 'darkness']}, {'raw': 'bpttom left dark', 'sent': 'bpttom left dark', 'sent_id': 72, 'tokens': ['bpttom', 'left', 'dark']}, {'raw': 'black van in front of cab', 'sent': 'black van in front of cab', 'sent_id': 73, 'tokens': ['black', 'van', 'in', 'front', 'of', 'cab']}]\n",
      "category_id: 3\n",
      "raw_anns: {\"segmentation\": [[59.15, 500.0, 0.48, 500.0, 0.0, 375.26, 96.66, 373.89, 104.85, 380.71, 117.13, 384.81, 127.36, 395.04, 134.86, 403.91, 137.59, 410.04, 112.41, 433.82, 108.59, 435.48, 105.11, 441.62, 103.45, 447.26, 95.99, 447.09, 62.98, 457.54]], \"area\": 12101.243650000002, \"iscrowd\": 0, \"image_id\": 581563, \"bbox\": [0.0, 373.89, 137.59, 126.11], \"category_id\": 3, \"id\": 1345868}\n",
      "raw_image_info: {\"license\": 3, \"file_name\": \"COCO_train2014_000000581563.jpg\", \"coco_url\": \"http://mscoco.org/images/581563\", \"height\": 500, \"width\": 333, \"date_captured\": \"2013-11-16 17:51:55\", \"flickr_url\": \"http://farm1.staticflickr.com/125/337273203_7eb35b845b_z.jpg\", \"id\": 581563}\n",
      "raw_sentences: [{\"tokens\": [\"lower\", \"left\", \"corner\", \"darkness\"], \"raw\": \"lower left corner darkness\", \"sent_id\": 71, \"sent\": \"lower left corner darkness\"}, {\"tokens\": [\"bpttom\", \"left\", \"dark\"], \"raw\": \"bpttom left dark\", \"sent_id\": 72, \"sent\": \"bpttom left dark\"}, {\"tokens\": [\"black\", \"van\", \"in\", \"front\", \"of\", \"cab\"], \"raw\": \"black van in front of cab\", \"sent_id\": 73, \"sent\": \"black van in front of cab\"}]\n",
      "image_path: coco/train2014/COCO_train2014_000000581563.jpg\n",
      "bbox: [0.0, 373.89, 137.59, 500.0]\n",
      "captions: ['lower left corner darkness', 'bpttom left dark', 'black van in front of cab']\n",
      "global_image_id: coco.581563\n",
      "anns_id: refcoco.1345868\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "for key, value in dataset[0].items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0a91001",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1810/1810 [00:00<00:00, 2452.03it/s]\n"
     ]
    }
   ],
   "source": [
    "converted_data = []\n",
    "\n",
    "for sample in tqdm(dataset):\n",
    "    id = make_id()\n",
    "\n",
    "    raw_image_info = json.loads(sample[\"raw_image_info\"])\n",
    "    image_file_name = raw_image_info[\"file_name\"]\n",
    "    original_image_width_height = (raw_image_info[\"width\"], raw_image_info[\"height\"])\n",
    "    image_path = os.path.join(\"mscoco2014/train2014\",image_file_name)\n",
    "    bbox = sample[\"bbox\"]\n",
    "    caption_list = [sentences[\"raw\"] for sentences in sample[\"sentences\"]]\n",
    "    \n",
    "    for caption in caption_list:\n",
    "        question = make_question(caption)\n",
    "        answer = make_answer(bbox, original_image_width_height)\n",
    "        conversation = make_conversation(id,image_path,question,answer)\n",
    "        converted_data.append(conversation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a3e89bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(converted_data): 5095\n",
      "id: 939e6612-a879-4546-92df-54c01a92d081\n",
      "image: mscoco2014/train2014/COCO_train2014_000000581563.jpg\n",
      "conversations: [{'from': 'human', 'value': '<image>\\nProvide the bounding box coordinate of the region this sentence describes: lower left corner darkness'}, {'from': 'gpt', 'value': '[0.000,0.748,0.413,1.000]'}]\n",
      "id: 939e6612-a879-4546-92df-54c01a92d081\n",
      "image: mscoco2014/train2014/COCO_train2014_000000581563.jpg\n",
      "conversations: [{'from': 'human', 'value': '<image>\\nProvide the bounding box coordinate of the region this sentence describes: bpttom left dark'}, {'from': 'gpt', 'value': '[0.000,0.748,0.413,1.000]'}]\n",
      "id: 939e6612-a879-4546-92df-54c01a92d081\n",
      "image: mscoco2014/train2014/COCO_train2014_000000581563.jpg\n",
      "conversations: [{'from': 'human', 'value': '<image>\\nProvide the bounding box coordinate of the region this sentence describes: black van in front of cab'}, {'from': 'gpt', 'value': '[0.000,0.748,0.413,1.000]'}]\n",
      "id: ea2317a9-a06c-4270-b745-c5092800d0b4\n",
      "image: mscoco2014/train2014/COCO_train2014_000000581563.jpg\n",
      "conversations: [{'from': 'human', 'value': '<image>\\nProvide the bounding box coordinate of the region this sentence describes: Taxi'}, {'from': 'gpt', 'value': '[0.167,0.763,1.000,1.000]'}]\n",
      "id: ea2317a9-a06c-4270-b745-c5092800d0b4\n",
      "image: mscoco2014/train2014/COCO_train2014_000000581563.jpg\n",
      "conversations: [{'from': 'human', 'value': '<image>\\nProvide the bounding box coordinate of the region this sentence describes: the taxi cab bottom right'}, {'from': 'gpt', 'value': '[0.167,0.763,1.000,1.000]'}]\n"
     ]
    }
   ],
   "source": [
    "print(\"len(converted_data):\",len(converted_data))\n",
    "for i in range(5):\n",
    "    for key, value in converted_data[i].items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3059e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(save_json_path, \"w\") as f:\n",
    "    json.dump(converted_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ea1efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "\n",
    "import uuid\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9dbeb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(loaded_data): 5095\n"
     ]
    }
   ],
   "source": [
    "with open(save_json_path, \"r\") as f:\n",
    "    loaded_data = json.load(f)\n",
    "print(\"len(loaded_data):\",len(loaded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b60dd9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5095/5095 [00:00<00:00, 24212.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist_image_count: 5095\n",
      "non_exist_image_count: 0\n",
      "exist_image_count / len(loaded_data): 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image_folder_root = \"/data_ssd\"\n",
    "\n",
    "exist_image_count = 0\n",
    "for i in tqdm(range(len(loaded_data))):\n",
    "    image_file_name = loaded_data[i][\"image\"]\n",
    "    image_path = os.path.join(image_folder_root,image_file_name)\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image file does not exist: {image_path}\")\n",
    "        continue\n",
    "    exist_image_count += 1\n",
    "print(\"exist_image_count:\", exist_image_count)\n",
    "print(\"non_exist_image_count:\", len(loaded_data) - exist_image_count)\n",
    "print(\"exist_image_count / len(loaded_data):\", exist_image_count / len(loaded_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd251f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imgviz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "from PIL import Image\n",
    "\n",
    "def visualize_bbox(image, bbox, caption):\n",
    "    bboxes = np.array([bbox[1],bbox[0],bbox[3],bbox[2]]).astype(np.int32).reshape(-1, 4)\n",
    "    labels = [2]\n",
    "    image = imgviz.instances2rgb(np.array(image), bboxes=bboxes, labels=labels,captions=[caption],font_size=16)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    \n",
    "def extract_bbox_from_text(ans):\n",
    "    pattern = re.compile(r'\\[(((0|1)\\.(\\d){3}\\,){3}((0|1)\\.(\\d){3}))\\]')\n",
    "    match_list = pattern.findall(ans)\n",
    "\n",
    "    if len(match_list) > 0:\n",
    "        answer = [list(map(float,match[0].split(\",\"))) for match in match_list]\n",
    "    else:\n",
    "        answer = \"FAILED\"\n",
    "    return answer\n",
    "\n",
    "def bbox_relative_to_absolute(relative_bbox, image_width_height):\n",
    "    width, height = image_width_height\n",
    "    x1 = relative_bbox[0] * width\n",
    "    y1 = relative_bbox[1] * height\n",
    "    x2 = relative_bbox[2] * width\n",
    "    y2 = relative_bbox[3] * height\n",
    "    absolute_bbox = [x1, y1, x2, y2]\n",
    "    return absolute_bbox\n",
    "\n",
    "\n",
    "\n",
    "sample_data = loaded_data[-500]\n",
    "\n",
    "image_path = sample_data[\"image\"]\n",
    "image_path = os.path.join(image_folder_root,image_path)\n",
    "image = Image.open(image_path)\n",
    "original_image_width_height = (image.width, image.height)\n",
    "\n",
    "answer = sample_data[\"conversations\"][1][\"value\"]\n",
    "relative_bbox = extract_bbox_from_text(answer)[0]\n",
    "absolute_bbox = bbox_relative_to_absolute(relative_bbox, original_image_width_height)\n",
    "\n",
    "print(sample_data[\"conversations\"][0][\"value\"])\n",
    "visualize_bbox(image, absolute_bbox, sample_data[\"conversations\"][0][\"value\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ab4f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

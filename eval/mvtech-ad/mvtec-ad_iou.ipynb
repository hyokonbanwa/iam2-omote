{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89e7740c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "from torchvision.ops import box_iou\n",
    "import torch\n",
    "def save_json(file_path, data):\n",
    "    \"\"\"\n",
    "    Save data to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "        data (dict): Data to save.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Data loaded from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "    \n",
    "def sort_list_of_dicts(data, key, reverse=False):\n",
    "    \"\"\"\n",
    "    Sort a list of dictionaries by the specified key.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of dictionaries to sort.\n",
    "        key (str): Key to sort by.\n",
    "        reverse (bool): Sort in descending order if True, ascending if False.\n",
    "\n",
    "    Returns:\n",
    "        list: Sorted list of dictionaries.\n",
    "    \"\"\"\n",
    "    return sorted(data, key=lambda x: x[key], reverse=reverse)\n",
    "\n",
    "\n",
    "def calculate_score(correct_data, generated_data,args,current_date):\n",
    "    total_data_num = len(correct_data)\n",
    "    anomaly_data_num = 0\n",
    "    normal_data_num = 0\n",
    "\n",
    "    model_predict_anomaly_data_num = 0\n",
    "    model_predict_normal_data_num = 0\n",
    "\n",
    "    matched_data_num = 0\n",
    "    anomaly_matched_data_num = 0\n",
    "\n",
    "\n",
    "\n",
    "    for i in tqdm(range(total_data_num)):\n",
    "        assert correct_data[i][\"id\"] == generated_data[i][\"id\"], f\"ID mismatch at index {i}.\"\n",
    "        if correct_data[i][\"conversations\"][-1][\"value\"] == \"None\":\n",
    "            normal_data_num += 1\n",
    "        else:\n",
    "            anomaly_data_num += 1\n",
    "        \n",
    "        if generated_data[i][\"conversations\"][-1][\"value\"] != \"None\":\n",
    "            model_predict_anomaly_data_num += 1\n",
    "        else:\n",
    "            model_predict_normal_data_num += 1\n",
    "\n",
    "        #正常画像の検出判定\n",
    "        if (correct_data[i][\"conversations\"][-1][\"value\"] == \"None\") and  (generated_data[i][\"conversations\"][-1][\"value\"] == \"None\" or generated_data[i][\"conversations\"][-1][\"value\"] == \"None.\"):\n",
    "            matched_data_num += 1\n",
    "        # 異常画像の検出判定\n",
    "        elif (correct_data[i][\"conversations\"][-1][\"value\"] != \"None\") and (generated_data[i][\"conversations\"][-1][\"value\"] != \"None\" and generated_data[i][\"conversations\"][-1][\"value\"] != \"None.\"):\n",
    "            matched_data_num += 1\n",
    "            anomaly_matched_data_num += 1\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Total data number: {total_data_num}\")\n",
    "    print(f\"Normal data number: {normal_data_num}\")\n",
    "    print(f\"Anomaly data number: {anomaly_data_num}\")\n",
    "\n",
    "    print(f\"Model predict normal data number: {model_predict_normal_data_num}\")\n",
    "    print(f\"Model predict anomaly data number: {model_predict_anomaly_data_num}\")\n",
    "\n",
    "    print(f\"Matched data number: {matched_data_num}\")\n",
    "    print(f\"Anomaly matched data number: {anomaly_matched_data_num}\")\n",
    "    print(\"-\" * 50)\n",
    "    accuracy = matched_data_num / total_data_num\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    precision = anomaly_matched_data_num / model_predict_anomaly_data_num if model_predict_anomaly_data_num > 0 else 0\n",
    "    print(f\"Precision: {precision}\")\n",
    "    recall = anomaly_matched_data_num / anomaly_data_num if anomaly_data_num > 0 else 0\n",
    "    print(f\"Recall: {recall}\")\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    print(f\"F1 Score: {f1_score}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    output_data = {\n",
    "        \"filename\": args.generated_json,\n",
    "        \"correct_json\": args.gt_json,\n",
    "        \"timestamp\": current_date,\n",
    "        \"scores\": {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1_score\n",
    "        },\n",
    "        \"data_num\": {\n",
    "            \"total_data_num\": total_data_num,\n",
    "            \"normal_data_num\": normal_data_num,\n",
    "            \"anomaly_data_num\": anomaly_data_num,\n",
    "            \"model_predict_normal_data_num\": model_predict_normal_data_num,\n",
    "            \"model_predict_anomaly_data_num\": model_predict_anomaly_data_num,\n",
    "            \"matched_data_num\": matched_data_num,\n",
    "            \"anomaly_matched_data_num\": anomaly_matched_data_num\n",
    "        },\n",
    "    }\n",
    "    return output_data\n",
    "\n",
    "def main(args):\n",
    "    base_name = os.path.basename(__file__)\n",
    "    current_date = datetime.datetime.now().strftime('%Y-%m-%dT%H_%M_%S')\n",
    "    \n",
    "    \n",
    "    if args.output_path is None:\n",
    "        generated_json_folder = os.path.dirname(args.generated_json)\n",
    "        output_path = os.path.join(generated_json_folder,f\"{base_name.split('.')[0]}.json\")\n",
    "    else:\n",
    "        output_path = args.output_path\n",
    "    \n",
    "    print(\"Loading JSON data...\")\n",
    "    correct_json_path = args.gt_json\n",
    "    correct_data = load_json(correct_json_path)\n",
    "\n",
    "    generated_json_path = args.generated_json\n",
    "    generated_data = load_json(generated_json_path)\n",
    "\n",
    "    assert len(correct_data) == len(generated_data), \"Length of correct and generated data does not match.\"\n",
    "\n",
    "    correct_data = sort_list_of_dicts(correct_data, \"id\")\n",
    "    generated_data = sort_list_of_dicts(generated_data, \"id\")\n",
    "\n",
    "    output_data = calculate_score(correct_data, generated_data,args,current_date)\n",
    "    \n",
    "    print(f\"Saving sorted JSON data to \\\"{output_path}\\\"...\")\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "     # Save the output data to the specified output path\n",
    "    save_json(output_path, output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dae332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_json_path = \"/data_ssd/mvtec_ad/mvtec-test_llava-onevision.json\"\n",
    "correct_data = load_json(correct_json_path)\n",
    "\n",
    "generated_json_path = \"/data_ssd/iam_model/original/llava-onevision-qwen2-7b-ov-hf/eval_output/mvtec-test_llava-onevision/2025-05-26T20_43_50/eval_output.json\"\n",
    "generated_json_path = \"/home/omote/omote-data-ssd/iam-llms-finetune/experiment_output/llava-onevision_finetune-llm_guad_5epoch_2025-05-27T10_38_39/eval_output/mvtec-test_llava-onevision/2025-05-28T16_17_46/eval_output.json\"\n",
    "generated_data = load_json(generated_json_path)\n",
    "\n",
    "assert len(correct_data) == len(generated_data), \"Length of correct and generated data does not match.\"\n",
    "\n",
    "correct_data = sort_list_of_dicts(correct_data, \"id\")\n",
    "generated_data = sort_list_of_dicts(generated_data, \"id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "858dd3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_bbox_path = \"/data_ssd/mvtec_ad/mvtec_bbox.json\"\n",
    "gt_bbox_data = load_json(gt_bbox_path)\n",
    "gt_bbox_data = {\"/\".join([\"/dataset\"]+k.split(\"/\")[-4:]): v for k, v in gt_bbox_data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bea380e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1258\n"
     ]
    }
   ],
   "source": [
    "print(len(gt_bbox_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "35ee3364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dataset/mvtec_test_for_icl/bottle/broken_large/000.png\n"
     ]
    }
   ],
   "source": [
    "print(list(gt_bbox_data.keys())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af64fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_bbox_from_text(ans):\n",
    "    pattern = re.compile(r'\\[(((0|1)\\.(\\d){3}\\,\\s*){3}((0|1)\\.(\\d){3}))\\]')\n",
    "    match_list = pattern.findall(ans)\n",
    "\n",
    "    if len(match_list) > 0:\n",
    "        answer = [list(map(float,match[0].split(\",\"))) for match in match_list]\n",
    "    else:\n",
    "        answer = \"FAILED\"\n",
    "    return answer\n",
    "\n",
    "def calculate_iou(gt_bbox_list, pred_bbox_list):\n",
    "    iou_matrix = box_iou(torch.tensor(gt_bbox_list).float(), torch.tensor(pred_bbox_list).float())\n",
    "    iou_argsort_matrix = torch.argsort(iou_matrix.flatten(),descending=True).argsort().reshape(iou_matrix.shape)#iouが大きい順にソートしたインデックスを取得\n",
    "    # print(\"-\" * 50)\n",
    "    # print(iou_matrix)\n",
    "    pred_index_list =  torch.full((len(pred_bbox_list),), False, dtype=torch.bool)\n",
    "    gt_index_list = torch.full((len(gt_bbox_list),), False, dtype=torch.bool)\n",
    "\n",
    "    iou_info_list = []\n",
    "\n",
    "    for i in range(len(gt_bbox_list)):\n",
    "        max_iou_index = torch.where(iou_argsort_matrix == i)\n",
    "        if not gt_index_list[max_iou_index[0]] and not pred_index_list[max_iou_index[1]]:\n",
    "            iou_info_list.append( {\n",
    "                \"gt_index\": max_iou_index[0].item(),\n",
    "                \"pred_index\": max_iou_index[1].item(),\n",
    "                \"iou_value\": iou_matrix[max_iou_index].item()\n",
    "            })\n",
    "            gt_index_list[max_iou_index[0]] = True\n",
    "            pred_index_list[max_iou_index[1]] = True\n",
    "    # print(iou_info_list)\n",
    "    return iou_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ed4628b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1725/1725 [00:00<00:00, 7695.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "1888\n",
      "730\n",
      "Mean IoU: 0.12335502769358647\n",
      "Mean Generated IoU: 0.31903327710341267\n",
      "--------------------------------------------------\n",
      "Total data number: 1725\n",
      "Normal data number: 467\n",
      "Anomaly data number: 1258\n",
      "Model predict normal data number: 1005\n",
      "Model predict anomaly data number: 720\n",
      "Matched data number: 629\n",
      "Anomaly matched data number: 168\n",
      "--------------------------------------------------\n",
      "Accuracy: 0.3646376811594203\n",
      "Precision: 0.23333333333333334\n",
      "Recall: 0.13354531001589826\n",
      "F1 Score: 0.1698685540950455\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_data_num = len(correct_data)\n",
    "anomaly_data_num = 0\n",
    "normal_data_num = 0\n",
    "\n",
    "model_predict_anomaly_data_num = 0\n",
    "model_predict_normal_data_num = 0\n",
    "\n",
    "matched_data_num = 0\n",
    "anomaly_matched_data_num = 0\n",
    "\n",
    "all_iou_list = []\n",
    "generated_iou_list = []\n",
    "\n",
    "gt_iou_num_count= 0\n",
    "\n",
    "iou_threshold = 0.5\n",
    "\n",
    "for i in tqdm(range(total_data_num)):\n",
    "    assert correct_data[i][\"id\"] == generated_data[i][\"id\"], f\"ID mismatch at index {i}.\"\n",
    "    if correct_data[i][\"conversations\"][-1][\"value\"] == \"None\":\n",
    "        normal_data_num += 1\n",
    "    else:\n",
    "        anomaly_data_num += 1\n",
    "    \n",
    "    if \"None\" in generated_data[i][\"conversations\"][-1][\"value\"]:\n",
    "        \n",
    "        model_predict_normal_data_num += 1\n",
    "    else:\n",
    "        model_predict_anomaly_data_num += 1\n",
    "\n",
    "\n",
    "    #正常画像の検出判定\n",
    "    if (correct_data[i][\"conversations\"][-1][\"value\"] == \"None\") and  (\"None\" in generated_data[i][\"conversations\"][-1][\"value\"]):\n",
    "        matched_data_num += 1\n",
    "    # 異常画像の検出判定\n",
    "    elif (correct_data[i][\"conversations\"][-1][\"value\"] != \"None\"):\n",
    "        correct_bbox = gt_bbox_data[correct_data[i][\"id\"]]\n",
    "        generated_bbox = extract_bbox_from_text(generated_data[i][\"conversations\"][-1][\"value\"])\n",
    "        gt_iou_num_count += len(correct_bbox)\n",
    "        # if len(correct_bbox) >  1:\n",
    "        #     print(correct_data[i][\"id\"])\n",
    "        #     print(correct_bbox)\n",
    "        #     print(generated_bbox)\n",
    "        if generated_bbox == \"FAILED\":\n",
    "            iou_list = [0.0] * len(correct_bbox)\n",
    "        else:\n",
    "            iou_list = [item[\"iou_value\"] for item in calculate_iou(correct_bbox, generated_bbox)]\n",
    "            generated_iou_list.extend(iou_list)\n",
    "            if len(iou_list) < len(correct_bbox):\n",
    "                iou_list.extend([0.0] * (len(correct_bbox) - len(iou_list)))\n",
    "\n",
    "        all_iou_list.extend(iou_list)\n",
    "        iou_threshold_count = sum(1 for iou in iou_list if iou >= iou_threshold)\n",
    "        if iou_threshold_count > 0:\n",
    "            matched_data_num += 1\n",
    "            anomaly_matched_data_num += 1\n",
    "            \n",
    "        # if i > 100:\n",
    "        #     break\n",
    "        # matched_data_num += 1\n",
    "        # anomaly_matched_data_num += 1\n",
    "\n",
    "assert len(all_iou_list) == gt_iou_num_count, f\"Length of all_iou_list {len(all_iou_list)} does not match gt_iou_num_count {len(gt_iou_num_count)}.\"\n",
    "print(\"-\" * 50)\n",
    "print(len(all_iou_list))\n",
    "print(len(generated_iou_list))\n",
    "\n",
    "mean_all_iou = sum(all_iou_list) / len(all_iou_list) if len(all_iou_list) > 0 else 0\n",
    "print(f\"Mean IoU: {mean_all_iou}\")\n",
    "mean_generated_iou = sum(generated_iou_list) / len(generated_iou_list) if len(generated_iou_list) > 0 else 0\n",
    "print(f\"Mean Generated IoU: {mean_generated_iou}\")\n",
    "\n",
    "# iou_threshold_count = sum(1 for iou in all_iou_list if iou >= iou_threshold)\n",
    "# print(f\"Number of IoU >= {iou_threshold}: {iou_threshold_count}\")\n",
    "\n",
    "# matched_data_num += iou_threshold_count\n",
    "# anomaly_matched_data_num = iou_threshold_count if iou_threshold_count > 0 else 0\n",
    "\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total data number: {total_data_num}\")\n",
    "print(f\"Normal data number: {normal_data_num}\")\n",
    "print(f\"Anomaly data number: {anomaly_data_num}\")\n",
    "\n",
    "print(f\"Model predict normal data number: {model_predict_normal_data_num}\")\n",
    "print(f\"Model predict anomaly data number: {model_predict_anomaly_data_num}\")\n",
    "\n",
    "print(f\"Matched data number: {matched_data_num}\")\n",
    "print(f\"Anomaly matched data number: {anomaly_matched_data_num}\")\n",
    "print(\"-\" * 50)\n",
    "accuracy = matched_data_num / total_data_num\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "precision = anomaly_matched_data_num / model_predict_anomaly_data_num if model_predict_anomaly_data_num > 0 else 0\n",
    "print(f\"Precision: {precision}\")\n",
    "recall = anomaly_matched_data_num / anomaly_data_num if anomaly_data_num > 0 else 0\n",
    "print(f\"Recall: {recall}\")\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eabf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU Matrix:\n",
      "tensor([[0.2500, 0.5625, 1.0000],\n",
      "        [1.0000, 0.4444, 0.2500]])\n",
      "IoU Argsort Matrix:\n",
      "tensor([[4, 2, 0],\n",
      "        [1, 3, 5]])\n",
      "\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "[{'gt_index': 0, 'pred_index': 2, 'iou_value': 1.0}, {'gt_index': 1, 'pred_index': 0, 'iou_value': 1.0}]\n"
     ]
    }
   ],
   "source": [
    "bbox_1 = [0.0, 0.0, 1.0, 1.0]\n",
    "bbox_2 = [0.0, 0.0, 0.5, 0.5]\n",
    "bbox_3 = [0.0, 0.0, 0.75, 0.75]\n",
    "\n",
    "gt_bbox_list = [bbox_1, bbox_2, bbox_3]\n",
    "pred_bbox_list = [bbox_2, bbox_3, bbox_1]\n",
    "\n",
    "iou_matrix = box_iou(torch.tensor(gt_bbox_list).float(), torch.tensor(pred_bbox_list).float())\n",
    "print(\"IoU Matrix:\")\n",
    "print(iou_matrix)\n",
    "iou_argsort_matrix = torch.argsort(iou_matrix.flatten(),descending=True).argsort().reshape(iou_matrix.shape)\n",
    "print(\"IoU Argsort Matrix:\")\n",
    "print(iou_argsort_matrix)\n",
    "print()\n",
    "print(\"-\" * 50)\n",
    "\n",
    "pred_index_list =  torch.full((len(pred_bbox_list),), False, dtype=torch.bool)\n",
    "gt_index_list = torch.full((len(gt_bbox_list),), False, dtype=torch.bool)\n",
    "\n",
    "iou_info_list = []\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(gt_bbox_list)):\n",
    "    max_iou_index = torch.where(iou_argsort_matrix == i)\n",
    "    if not gt_index_list[max_iou_index[0]] and not pred_index_list[max_iou_index[1]]:\n",
    "        iou_info_list.append( {\n",
    "            \"gt_index\": max_iou_index[0].item(),\n",
    "            \"pred_index\": max_iou_index[1].item(),\n",
    "            \"iou_value\": iou_matrix[max_iou_index].item()\n",
    "        })\n",
    "        gt_index_list[max_iou_index[0]] = True\n",
    "        pred_index_list[max_iou_index[1]] = True\n",
    "    # print(f\"Max IoU index for GT bbox {i}: {max_iou_index}\")\n",
    "    # break\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(iou_info_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "356c88d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2500, 0.5625, 1.0000, 1.0000, 0.4444, 0.2500, 0.4444, 1.0000, 0.5625])\n",
      "tensor([2, 3, 7, 1, 8, 4, 6, 0, 5])\n",
      "torch.return_types.sort(\n",
      "values=tensor([1.0000, 1.0000, 1.0000, 0.5625, 0.5625, 0.4444, 0.4444, 0.2500, 0.2500]),\n",
      "indices=tensor([2, 3, 7, 1, 8, 4, 6, 0, 5]))\n",
      "tensor([[2, 1, 0],\n",
      "        [0, 1, 2],\n",
      "        [1, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "print(iou_matrix.flatten())\n",
    "print(torch.argsort(iou_matrix.flatten(),descending=True))\n",
    "print(torch.sort(iou_matrix.flatten(),descending=True))\n",
    "print(torch.sort(iou_matrix,descending=True).indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284fdcd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e76eb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed538750",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_num = len(correct_data)\n",
    "anomaly_data_num = 0\n",
    "normal_data_num = 0\n",
    "\n",
    "model_predict_anomaly_data_num = 0\n",
    "model_predict_normal_data_num = 0\n",
    "\n",
    "matched_data_num = 0\n",
    "anomaly_matched_data_num = 0\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(total_data_num)):\n",
    "    assert correct_data[i][\"id\"] == generated_data[i][\"id\"], f\"ID mismatch at index {i}.\"\n",
    "    if correct_data[i][\"conversations\"][-1][\"value\"] == \"None\":\n",
    "        normal_data_num += 1\n",
    "    else:\n",
    "        anomaly_data_num += 1\n",
    "    \n",
    "    if generated_data[i][\"conversations\"][-1][\"value\"] != \"None\":\n",
    "        model_predict_anomaly_data_num += 1\n",
    "    else:\n",
    "        model_predict_normal_data_num += 1\n",
    "\n",
    "    #正常画像の検出判定\n",
    "    if (correct_data[i][\"conversations\"][-1][\"value\"] == \"None\") and  (generated_data[i][\"conversations\"][-1][\"value\"] == \"None\" or generated_data[i][\"conversations\"][-1][\"value\"] == \"None.\"):\n",
    "        matched_data_num += 1\n",
    "    # 異常画像の検出判定\n",
    "    elif (correct_data[i][\"conversations\"][-1][\"value\"] != \"None\") and (generated_data[i][\"conversations\"][-1][\"value\"] != \"None\" and generated_data[i][\"conversations\"][-1][\"value\"] != \"None.\"):\n",
    "        matched_data_num += 1\n",
    "        anomaly_matched_data_num += 1\n",
    "        \n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"Total data number: {total_data_num}\")\n",
    "print(f\"Normal data number: {normal_data_num}\")\n",
    "print(f\"Anomaly data number: {anomaly_data_num}\")\n",
    "\n",
    "print(f\"Model predict normal data number: {model_predict_normal_data_num}\")\n",
    "print(f\"Model predict anomaly data number: {model_predict_anomaly_data_num}\")\n",
    "\n",
    "print(f\"Matched data number: {matched_data_num}\")\n",
    "print(f\"Anomaly matched data number: {anomaly_matched_data_num}\")\n",
    "print(\"-\" * 50)\n",
    "accuracy = matched_data_num / total_data_num\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "precision = anomaly_matched_data_num / model_predict_anomaly_data_num if model_predict_anomaly_data_num > 0 else 0\n",
    "print(f\"Precision: {precision}\")\n",
    "recall = anomaly_matched_data_num / anomaly_data_num if anomaly_data_num > 0 else 0\n",
    "print(f\"Recall: {recall}\")\n",
    "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "output_data = {\n",
    "    \"filename\": args.generated_json,\n",
    "    \"correct_json\": args.gt_json,\n",
    "    \"timestamp\": current_date,\n",
    "    \"scores\": {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1_score\n",
    "    },\n",
    "    \"data_num\": {\n",
    "        \"total_data_num\": total_data_num,\n",
    "        \"normal_data_num\": normal_data_num,\n",
    "        \"anomaly_data_num\": anomaly_data_num,\n",
    "        \"model_predict_normal_data_num\": model_predict_normal_data_num,\n",
    "        \"model_predict_anomaly_data_num\": model_predict_anomaly_data_num,\n",
    "        \"matched_data_num\": matched_data_num,\n",
    "        \"anomaly_matched_data_num\": anomaly_matched_data_num\n",
    "    },\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "208b4346",
   "metadata": {},
   "source": [
    "# 追加\n",
    "Region false count: 983\n",
    "Name false count: 1073\n",
    "Name match count: 9880\n",
    "Region false delim count: 2242\n",
    "Name false delim count: 2377\n",
    "Name match delim count: 25126\n",
    "\n",
    "region falseを評価から除外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "208c64f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omote/cluster_project/iam2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.append(\"/home/omote/cluster_project/iam2/eval\")  # Adjust the path to include the parent directory\n",
    "#print(__file__.rsplit('/', 2)[0])\n",
    "from eval_utils.custom_oc_cost import get_cmap,get_ot_cost,DetectedInstance\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import regex as re\n",
    "from torchvision.ops import box_iou\n",
    "import torch\n",
    "from transformers import AutoProcessor\n",
    "import imgviz\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from pycocotools.coco import COCO\n",
    "from copy import deepcopy\n",
    "from sentence_transformers import SentenceTransformer,util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ce84d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(file_path, data):\n",
    "    \"\"\"\n",
    "    Save data to a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "        data (dict): Data to save.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "def load_json(file_path):\n",
    "    \"\"\"\n",
    "    Load data from a JSON file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the JSON file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Data loaded from the file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def bbox_absolute_to_relative(absolute_bbox, image_width_height):\n",
    "    width, height = image_width_height\n",
    "    x1 = absolute_bbox[0] / width\n",
    "    y1 = absolute_bbox[1] / height\n",
    "    x2 = absolute_bbox[2] / width\n",
    "    y2 = absolute_bbox[3] / height\n",
    "    relative_bbox = [x1, y1, x2, y2]\n",
    "    return relative_bbox\n",
    "\n",
    "def bbox_relative_to_absolute(relative_bbox, image_width_height):\n",
    "    width, height = image_width_height\n",
    "    x1 = relative_bbox[0] * width\n",
    "    y1 = relative_bbox[1] * height\n",
    "    x2 = relative_bbox[2] * width\n",
    "    y2 = relative_bbox[3] * height\n",
    "    absolute_bbox = [x1, y1, x2, y2]\n",
    "    return absolute_bbox\n",
    "    \n",
    "def visualize_bbox(image, bbox_list, bbox_name_list,bbox_is_relative=True,with_id=False):\n",
    "    assert len(bbox_list) == len(bbox_name_list), \"bbox_list and bbox_name_list must have the same length\"\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image).convert(\"RGB\")\n",
    "\n",
    "    if bbox_is_relative:\n",
    "        # 画像のサイズを取得\n",
    "        image_width_height = (image.width, image.height)\n",
    "        # 相対座標を絶対座標に変換\n",
    "        bbox_list = [bbox_relative_to_absolute(bbox, image_width_height) for bbox in bbox_list]\n",
    "        \n",
    "    #bbox_name_listをソート、bbox_listも同じ順番にソート\n",
    "    # bbox_name_list, bbox_list = zip(*sorted(zip(bbox_name_list, bbox_list), key=lambda x: x[0]))\n",
    "    # bbox_name_list = list(bbox_name_list)\n",
    "    # bbox_list = list(bbox_list)\n",
    "    name_to_label_id_dict = {}\n",
    "    label_id = 0\n",
    "    for bbox_name in bbox_name_list:\n",
    "        if bbox_name not in name_to_label_id_dict:\n",
    "            name_to_label_id_dict[bbox_name] = label_id\n",
    "            label_id += 1    \n",
    "    \n",
    "    # bbox_listの座標をy1, x1, y2, x2の形式に変換\n",
    "    bboxes = []\n",
    "    labels = []\n",
    "    # label_id = -1\n",
    "    # old_label = None\n",
    "    count_object_dict = {}\n",
    "    id_bbox_name_list = []\n",
    "    for bbox ,bbox_name in zip(bbox_list, bbox_name_list):\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        bboxes.append([y1, x1, y2, x2])\n",
    "        # if old_label != bbox_name:\n",
    "        #     label_id += 1\n",
    "        #     old_label = bbox_name\n",
    "        label_id = name_to_label_id_dict[bbox_name]\n",
    "        if bbox_name not in count_object_dict:\n",
    "            count_object_dict[bbox_name] = 0\n",
    "        else:\n",
    "            count_object_dict[bbox_name] += 1\n",
    "        if with_id:\n",
    "            bbox_name = f\"{bbox_name}_{count_object_dict[bbox_name]}\"\n",
    "            id_bbox_name_list.append(bbox_name)\n",
    "        labels.append(label_id)\n",
    "    # bboxes = np.array([bbox[1],bbox[0],bbox[3],bbox[2]]).astype(np.int32).reshape(-1, 4)\n",
    "    \n",
    "    base_resolution = 100 * 100\n",
    "    base_font_size = 3\n",
    "    image_resolution = image.width * image.height\n",
    "    font_size = int( base_font_size * (image_resolution / base_resolution) ** 0.5)\n",
    "    \n",
    "    if with_id:\n",
    "        bbox_name_list = id_bbox_name_list\n",
    "    image = imgviz.instances2rgb(np.array(image), bboxes=bboxes, labels=labels,font_size=font_size,captions=bbox_name_list)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "def sort_list_of_dicts(data, key, reverse=False):\n",
    "    \"\"\"\n",
    "    Sort a list of dictionaries by the specified key.\n",
    "\n",
    "    Args:\n",
    "        data (list): List of dictionaries to sort.\n",
    "        key (str): Key to sort by.\n",
    "        reverse (bool): Sort in descending order if True, ascending if False.\n",
    "\n",
    "    Returns:\n",
    "        list: Sorted list of dictionaries.\n",
    "    \"\"\"\n",
    "    return sorted(data, key=lambda x: x[key], reverse=reverse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb319662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(gt_bbox_list, pred_bbox_list):\n",
    "    iou_matrix = box_iou(torch.tensor(gt_bbox_list).float(), torch.tensor(pred_bbox_list).float())\n",
    "    iou_matrix = torch.nan_to_num(iou_matrix, nan=0.0)  # NaNを0に置き換える\n",
    "    iou_argsort_matrix = torch.argsort(iou_matrix.flatten(),descending=True).argsort().reshape(iou_matrix.shape)#iouが大きい順にソートしたインデックスを取得\n",
    "    # print(iou_argsort_matrix)\n",
    "    # print(\"-\" * 50)\n",
    "    # print(iou_matrix)\n",
    "    pred_index_list =  torch.full((len(pred_bbox_list),), False, dtype=torch.bool)\n",
    "    gt_index_list = torch.full((len(gt_bbox_list),), False, dtype=torch.bool)\n",
    "\n",
    "    short_index_list = pred_index_list if len(pred_bbox_list) < len(gt_bbox_list) else gt_index_list\n",
    "    iou_info_list = []\n",
    "\n",
    "    # print(iou_matrix.numel())\n",
    "    for i in range(iou_matrix.numel()):\n",
    "        max_iou_index = torch.where(iou_argsort_matrix == i)\n",
    "        if not gt_index_list[max_iou_index[0]] and not pred_index_list[max_iou_index[1]]:\n",
    "            iou_info_list.append( {\n",
    "                \"gt_index\": max_iou_index[0].item(),\n",
    "                \"pred_index\": max_iou_index[1].item(),\n",
    "                \"iou_value\": iou_matrix[max_iou_index].item()\n",
    "            })\n",
    "            gt_index_list[max_iou_index[0]] = True\n",
    "            pred_index_list[max_iou_index[1]] = True\n",
    "            # print(f\"index {i} - gt_index: {max_iou_index[0].item()}, pred_index: {max_iou_index[1].item()}, iou_value: {iou_matrix[max_iou_index].item()}\")\n",
    "        \n",
    "        if torch.all(short_index_list):\n",
    "            break\n",
    "        \n",
    "    assert len(iou_info_list) == min(len(gt_bbox_list), len(pred_bbox_list)), f\"Length mismatch: {len(iou_info_list)} != {min(len(gt_bbox_list), len(pred_bbox_list))}\"\n",
    "    # print(iou_info_list)\n",
    "    # for iou_info in iou_info_list:\n",
    "    #     if math.isnan(iou_info[\"iou_value\"]):\n",
    "    #         print(f\"IOU value is NaN for gt index {iou_info['gt_index']} and pred index {iou_info['pred_index']}\")\n",
    "    #         print(iou_matrix[iou_info['gt_index'], iou_info['pred_index']])\n",
    "    #         print(iou_matrix[iou_info['gt_index'], iou_info['pred_index']].item())\n",
    "    #         print(iou_info[\"iou_value\"])\n",
    "    #         print(iou_matrix)\n",
    "    \n",
    "    return iou_info_list,iou_matrix,iou_argsort_matrix,pred_index_list, gt_index_list\n",
    "\n",
    "def oc_cost(pred_instance_list,tgt_instance_list, alpha=0.5,beta=0.6):\n",
    "    cmap_func = lambda x, y: get_cmap(x, y, alpha=alpha, beta=beta,label_or_sim=\"label\")\n",
    "    otc = get_ot_cost(pred_instance_list, tgt_instance_list, cmap_func)\n",
    "    return otc\n",
    "\n",
    "def similariry_score(str1, str2, model: SentenceTransformer):\n",
    "    # compute embedding for both lists\n",
    "    embedding_1 = model.encode(str1, show_progress_bar=False)\n",
    "    embedding_2 = model.encode(str2, show_progress_bar=False)\n",
    "    score = util.pytorch_cos_sim(embedding_1, embedding_2).item()\n",
    "    \n",
    "    #スコア丸め込み\n",
    "    # score = min(score, 1.0)\n",
    "    # score = max(score, 0.0)\n",
    "    \n",
    "    return score\n",
    "\n",
    "def create_get_most_similar_category_func(category_list, sentence_transformer_model_path):\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    similarity_model = SentenceTransformer(sentence_transformer_model_path).to(device)\n",
    "    category_embeddings = similarity_model.encode(category_list, show_progress_bar=False, convert_to_tensor=True)\n",
    "    def get_most_similar_category(category_name):\n",
    "        category_embedding = similarity_model.encode(category_name, show_progress_bar=False, convert_to_tensor=True)\n",
    "        scores = util.pytorch_cos_sim(category_embedding, category_embeddings).squeeze(0)\n",
    "        most_similar_index = torch.argmax(scores).item()\n",
    "        return category_list[most_similar_index], scores[most_similar_index].item(), scores\n",
    "    return get_most_similar_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1a4037a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_most_similar_category = create_get_most_similar_category_func(\n",
    "    [\"airplane\", \"bicycle\", \"bird\", \"boat\"],\n",
    "    \"/data_ssd/huggingface_model_weights/sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c5e73c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match category: airplane, score: 0.8521708250045776\n"
     ]
    }
   ],
   "source": [
    "category, score, scores = get_most_similar_category(\"plane\")\n",
    "print(f\"Best match category: {category}, score: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae066cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_per_image_class_result_and_oc_cost(all_gt_annotations, all_pred_annotations, cat_name2id, iou_threshold=0.5):\n",
    "    \"\"\"\n",
    "    Evaluate per-image and per-category results and calculate occlusion cost.\n",
    "\n",
    "    Args:\n",
    "        all_gt_annotations (dict): Ground truth annotations.\n",
    "        all_pred_annotations (dict): Predicted annotations.\n",
    "        cat_name2id (dict): Category name to ID mapping.\n",
    "        iou_threshold (float): IOU threshold for true positives.\n",
    "\n",
    "    Returns:\n",
    "        dict: Per-image results and occlusion costs.\n",
    "    \"\"\"\n",
    "    per_image_result_dict = {}\n",
    "    break_index = 10\n",
    "    oc_cost_list = []\n",
    "    for index, gt_per_image_annotation_list in tqdm(all_gt_annotations.items()):\n",
    "        pred_per_image_annotation_list = all_pred_annotations.get(index, [])\n",
    "        \n",
    "        # 画像ごとの評価\n",
    "        pred_instance_list = [DetectedInstance(\n",
    "            label=ann[\"category_id\"],\n",
    "            x1=ann[\"bbox_xyxy\"][0],\n",
    "            y1=ann[\"bbox_xyxy\"][1],\n",
    "            x2=ann[\"bbox_xyxy\"][2],\n",
    "            y2=ann[\"bbox_xyxy\"][3]) for ann in pred_per_image_annotation_list]\n",
    "        tgt_instance_list = [DetectedInstance(\n",
    "            label=ann[\"category_id\"],\n",
    "            x1=ann[\"bbox_xyxy\"][0],\n",
    "            y1=ann[\"bbox_xyxy\"][1],\n",
    "            x2=ann[\"bbox_xyxy\"][2],\n",
    "            y2=ann[\"bbox_xyxy\"][3]) for ann in gt_per_image_annotation_list]\n",
    "        \n",
    "        oc_cost_value = oc_cost(pred_instance_list, tgt_instance_list, alpha=0.5, beta=0.6)\n",
    "        oc_cost_list.append(oc_cost_value)\n",
    "        \n",
    "        #画像ごと・カテゴリごとの評価準備\n",
    "        gt_per_category_dict = {}\n",
    "        pred_per_category_dict = {}\n",
    "        per_category_result_dict = {}\n",
    "        \n",
    "        for category_id in cat_name2id.values():\n",
    "            gt_per_category_dict[category_id] = None\n",
    "            pred_per_category_dict[category_id] = None\n",
    "            per_category_result_dict[category_id] = None\n",
    "            \n",
    "        for annotation in gt_per_image_annotation_list:\n",
    "            if gt_per_category_dict[annotation[\"category_id\"]] is None:\n",
    "                gt_per_category_dict[annotation[\"category_id\"]] = []\n",
    "            gt_per_category_dict[annotation[\"category_id\"]].append(annotation)\n",
    "        \n",
    "        for annotation in pred_per_image_annotation_list:\n",
    "            if pred_per_category_dict[annotation[\"category_id\"]] is None:\n",
    "                pred_per_category_dict[annotation[\"category_id\"]] = []\n",
    "            pred_per_category_dict[annotation[\"category_id\"]].append(annotation)\n",
    "        \n",
    "        \n",
    "        for category_id, gt_annotations in gt_per_category_dict.items():\n",
    "            pred_annotations = pred_per_category_dict[category_id]\n",
    "            if gt_annotations is None and  pred_annotations is None:\n",
    "                continue\n",
    "            \n",
    "            per_category_result = {\n",
    "                \"iou_list\": [],\n",
    "                \"pred_iou_list\": [],\n",
    "                \"tp_num\": 0,\n",
    "                \"fp_num\": 0,\n",
    "                \"fn_num\": 0,\n",
    "            }\n",
    "            if gt_annotations is None and pred_per_category_dict[category_id] is not None:\n",
    "                per_category_result[\"fp_num\"] = len(pred_per_category_dict[category_id])\n",
    "            elif gt_annotations is not None:\n",
    "                if pred_per_category_dict[category_id] is None:\n",
    "                    per_category_result[\"fn_num\"] = len(gt_annotations)\n",
    "                    per_category_result[\"iou_list\"] = [0.0] * len(gt_annotations)\n",
    "                else: \n",
    "                    gt_bbox_list = [ann[\"bbox_xyxy\"] for ann in gt_annotations]\n",
    "                    pred_bbox_list = [ann[\"bbox_xyxy\"] for ann in pred_annotations]\n",
    "                    iou_info_list,iou_matrix,iou_argsort_matrix,pred_index_list, gt_index_listt = calculate_iou(gt_bbox_list, pred_bbox_list)\n",
    "                    assert ((len(gt_bbox_list) < len(pred_bbox_list) and len(iou_info_list) == len(gt_bbox_list)) or (len(gt_bbox_list) >= len(pred_bbox_list) and len(iou_info_list) == len(pred_bbox_list))), f\"Length mismatch in category {category_id}, index {index}: len(iou_info_list)={len(iou_info_list)}, len(gt_bbox_list)={len(gt_bbox_list)}, len(pred_bbox_list)={len(pred_bbox_list)}\"\n",
    "                    # if not((len(gt_bbox_list) < len(pred_bbox_list) and len(iou_info_list) == len(gt_bbox_list)) or \\\n",
    "                    #     (len(gt_bbox_list) >= len(pred_bbox_list) and len(iou_info_list) == len(pred_bbox_list))):\n",
    "                        # print(f\"index: {index}, category_id: {category_id}, len(iou_info_list): {len(iou_info_list)}, len(gt_bbox_list): {len(gt_bbox_list)}, len(pred_bbox_list): {len(pred_bbox_list)}\")\n",
    "                        # print(f\"pred_bbox_list: {pred_bbox_list}\")\n",
    "                        # print(f\"gt_bbox_list: {gt_bbox_list}\")\n",
    "                        # print(f\"iou_info_list: {iou_info_list}\")\n",
    "                        # print(f\"iou_matrix: {iou_matrix}\")\n",
    "                        # print(f\"iou_argsort_matrix: {iou_argsort_matrix}\")\n",
    "                        # print(f\"pred_index_list: {pred_index_list}\")\n",
    "                        # print(f\"gt_index_list: {gt_index_listt}\")\n",
    "                        # raise ValueError(\"IOU information length mismatch\")\n",
    "                    iou_list = [info[\"iou_value\"] for info in iou_info_list]\n",
    "                    per_category_result[\"pred_iou_list\"] = deepcopy(iou_list)\n",
    "                    for iou in iou_list:\n",
    "                        assert not math.isnan(iou), f\"IOU value is NaN in category {category_id}, index {index}\"\n",
    "                    if len(iou_list) < len(gt_bbox_list):\n",
    "                        iou_list += [0.0] * (len(gt_bbox_list) - len(iou_list))\n",
    "                    \n",
    "                    \n",
    "                    # for iou in iou_list:\n",
    "                    #     assert not math.isnan(iou), f\"IOU value is NaN in category {category_id}, index {index}\"\n",
    "                    per_category_result[\"iou_list\"] = iou_list\n",
    "                    tp_num = sum(1 for iou in iou_list if iou >= iou_threshold)\n",
    "                    per_category_result[\"tp_num\"] = tp_num\n",
    "                    per_category_result[\"fp_num\"] = len(pred_bbox_list) - tp_num\n",
    "                    per_category_result[\"fn_num\"] = len(gt_bbox_list) - tp_num\n",
    "                    # if index == 9 and category_id == 84:\n",
    "                    #     visualize_bbox(\n",
    "                    #         os.path.join(image_folder_root, images[index][\"file_name\"]),\n",
    "                    #         pred_bbox_list,\n",
    "                    #         [ann[\"category_name\"] for ann in pred_annotations],\n",
    "                    #         bbox_is_relative=True,\n",
    "                    #         with_id=True\n",
    "                    #     )\n",
    "                    #     print(per_category_result)\n",
    "                    #     print(pred_bbox_list == gt_bbox_list)\n",
    "                    #     print(len(pred_bbox_list), len(gt_bbox_list))\n",
    "                    #     print(iou_info_list)\n",
    "            \n",
    "            per_category_result_dict[category_id] = per_category_result\n",
    "        \n",
    "        per_image_result_dict[index] = per_category_result_dict\n",
    "        # if index >= break_index:\n",
    "        #     break\n",
    "    return per_image_result_dict, oc_cost_list \n",
    "\n",
    "def convert_per_class_result_dict(per_image_result_dict):\n",
    "    per_category_result_dict = {}\n",
    "    for index, per_image_result in per_image_result_dict.items():\n",
    "        for category_id, result in per_image_result.items():\n",
    "            if category_id not in per_category_result_dict:\n",
    "                per_category_result_dict[category_id] = {\n",
    "                    \"iou_list\": [],\n",
    "                    \"pred_iou_list\": [],\n",
    "                    \"tp_num\": 0,\n",
    "                    \"fp_num\": 0,\n",
    "                    \"fn_num\": 0,\n",
    "                }\n",
    "            \n",
    "            if result is None:\n",
    "                continue\n",
    "            # if result[\"fp_num\"] > 0 or result[\"fn_num\"]:\n",
    "            #     print(index, category_id, result)\n",
    "            per_category_result_dict[category_id][\"tp_num\"] += result[\"tp_num\"]\n",
    "            per_category_result_dict[category_id][\"fp_num\"] += result[\"fp_num\"]\n",
    "            per_category_result_dict[category_id][\"fn_num\"] += result[\"fn_num\"]\n",
    "            per_category_result_dict[category_id][\"iou_list\"].extend(result[\"iou_list\"])\n",
    "            per_category_result_dict[category_id][\"pred_iou_list\"].extend(result[\"pred_iou_list\"])\n",
    "    return per_category_result_dict\n",
    "\n",
    "def calculate_score(per_category_result_dict,oc_cost_list,category_id2name):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, F1 score, and mean IOU for each category and overall dataset.\n",
    "\n",
    "    Args:\n",
    "        per_category_result_dict (dict): Per-category results.\n",
    "        oc_cost_list (list): List of occlusion costs.\n",
    "\n",
    "    Returns:\n",
    "        dict: Summary scores and data numbers for the dataset.\n",
    "    \"\"\"\n",
    "    per_category_score_dict = {}\n",
    "\n",
    "    dataset_score = {\n",
    "        \"summary_scores\":{\n",
    "            \"micro_precision\": 0.0,\n",
    "            \"micro_recall\": 0.0,\n",
    "            \"micro_f1\": 0.0,\n",
    "            \"m_iou\": [],\n",
    "            \"m_pred_iou\": [],\n",
    "            \"oc_cost\": np.mean(oc_cost_list) if len(oc_cost_list) > 0 else 0.0,\n",
    "            \"macro_precision\": [],\n",
    "            \"macro_recall\": [],\n",
    "            \"macro_f1\": [],\n",
    "            \"cm_iou\": [],\n",
    "            \"cm_pred_iou\": [],\n",
    "        },\n",
    "        \"summary_data_num\":{\n",
    "            \"tp_num\": 0,\n",
    "            \"fp_num\": 0,\n",
    "            \"fn_num\": 0,\n",
    "            \"unkonown_fp_num\": per_category_result_dict[-1][\"fp_num\"] if -1 in per_category_result_dict else 0,\n",
    "            \"iou_num\": 0,\n",
    "            \"pred_iou_num\": 0,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    for category_id, result in per_category_result_dict.items():\n",
    "        #クラスごと\n",
    "        tp_num = result[\"tp_num\"]\n",
    "        fp_num = result[\"fp_num\"]\n",
    "        fn_num = result[\"fn_num\"]\n",
    "        iou_list = result[\"iou_list\"]\n",
    "        pred_iou_list = result[\"pred_iou_list\"]\n",
    "    \n",
    "        cm_iou = np.mean(iou_list) if len(iou_list) > 0 else 0.0\n",
    "        cm_pred_iou = np.mean(pred_iou_list) if len(pred_iou_list) > 0 else 0.0\n",
    "        # if math.isnan(m_iou):\n",
    "        #     print(f\"Category ID: {category_id} has NaN mIoU. Check the IOU list: {iou_list}\")\n",
    "        #     for iou in iou_list:\n",
    "        #         assert not math.isnan(iou), f\"IOU value is NaN in category {category_id}\"\n",
    "        precision = tp_num / (tp_num + fp_num) if (tp_num + fp_num) > 0 else 0.0\n",
    "        recall = tp_num / (tp_num + fn_num) if (tp_num + fn_num) > 0 else 0.0\n",
    "        f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        per_category_score = {\n",
    "            \"category_name\": category_id2name[category_id],\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1_score\": f1_score,\n",
    "            \"cm_iou\": cm_iou,\n",
    "            \"cm_pred_iou\": cm_pred_iou,\n",
    "            \"tp_num\": tp_num,\n",
    "            \"fp_num\": fp_num,\n",
    "            \"fn_num\": fn_num,\n",
    "        }\n",
    "        per_category_score_dict[category_id] = per_category_score\n",
    "        \n",
    "        #データセット全体\n",
    "        dataset_score[\"summary_data_num\"][\"tp_num\"] += tp_num\n",
    "        dataset_score[\"summary_data_num\"][\"fp_num\"] += fp_num\n",
    "        dataset_score[\"summary_data_num\"][\"fn_num\"] += fn_num\n",
    "        dataset_score[\"summary_data_num\"][\"iou_num\"] += len(iou_list)\n",
    "        dataset_score[\"summary_data_num\"][\"pred_iou_num\"] += len(pred_iou_list)\n",
    "        dataset_score[\"summary_scores\"][\"m_iou\"].extend(iou_list)\n",
    "        dataset_score[\"summary_scores\"][\"m_pred_iou\"].extend(pred_iou_list)\n",
    "        \n",
    "        #カテゴリごと\n",
    "        if category_id != -1:\n",
    "            dataset_score[\"summary_scores\"][\"macro_precision\"].append(precision)\n",
    "            dataset_score[\"summary_scores\"][\"macro_recall\"].append(recall)\n",
    "            dataset_score[\"summary_scores\"][\"macro_f1\"].append(f1_score)\n",
    "            dataset_score[\"summary_scores\"][\"cm_iou\"].append(cm_iou)\n",
    "            dataset_score[\"summary_scores\"][\"cm_pred_iou\"].append(cm_pred_iou)\n",
    "\n",
    "    #データセット全体\n",
    "    assert dataset_score[\"summary_data_num\"][\"tp_num\"] + dataset_score[\"summary_data_num\"][\"fn_num\"] == len(dataset_score[\"summary_scores\"][\"m_iou\"]) ,\\\n",
    "        f\"TP + FN mismatch: {dataset_score['summary_data_num']['tp_num']} + {dataset_score['summary_data_num']['fn_num']} != {len(dataset_score['summary_scores']['m_iou'])}\"\n",
    "    dataset_score[\"summary_scores\"][\"micro_precision\"] = dataset_score[\"summary_data_num\"][\"tp_num\"] / (dataset_score[\"summary_data_num\"][\"tp_num\"] + dataset_score[\"summary_data_num\"][\"fp_num\"]) if (dataset_score[\"summary_data_num\"][\"tp_num\"] + dataset_score[\"summary_data_num\"][\"fp_num\"]) > 0 else 0.0\n",
    "    dataset_score[\"summary_scores\"][\"micro_recall\"] = dataset_score[\"summary_data_num\"][\"tp_num\"] / (dataset_score[\"summary_data_num\"][\"tp_num\"] + dataset_score[\"summary_data_num\"][\"fn_num\"]) if (dataset_score[\"summary_data_num\"][\"tp_num\"] + dataset_score[\"summary_data_num\"][\"fn_num\"]) > 0 else 0.0\n",
    "    dataset_score[\"summary_scores\"][\"micro_f1\"] = (2 * dataset_score[\"summary_scores\"][\"micro_precision\"] * dataset_score[\"summary_scores\"][\"micro_recall\"]) / (dataset_score[\"summary_scores\"][\"micro_precision\"] + dataset_score[\"summary_scores\"][\"micro_recall\"]) if (dataset_score[\"summary_scores\"][\"micro_precision\"] + dataset_score[\"summary_scores\"][\"micro_recall\"]) > 0 else 0.0\n",
    "    dataset_score[\"summary_scores\"][\"m_iou\"] = np.mean(dataset_score[\"summary_scores\"][\"m_iou\"]) if len(dataset_score[\"summary_scores\"][\"m_iou\"]) > 0 else 0.0\n",
    "    dataset_score[\"summary_scores\"][\"m_pred_iou\"] = np.mean(dataset_score[\"summary_scores\"][\"m_pred_iou\"]) if len(dataset_score[\"summary_scores\"][\"m_pred_iou\"]) > 0 else 0.0\n",
    "    dataset_score[\"summary_scores\"][\"macro_precision\"] = np.mean(dataset_score[\"summary_scores\"][\"macro_precision\"]) if len(dataset_score[\"summary_scores\"][\"macro_precision\"]) > 0 else 0.0\n",
    "    dataset_score[\"summary_scores\"][\"macro_recall\"] = np.mean(dataset_score[\"summary_scores\"][\"macro_recall\"]) if len(dataset_score[\"summary_scores\"][\"macro_recall\"]) > 0 else 0.0\n",
    "    dataset_score[\"summary_scores\"][\"macro_f1\"] = np.mean(dataset_score[\"summary_scores\"][\"macro_f1\"]) if len(dataset_score[\"summary_scores\"][\"macro_f1\"]) > 0 else 0.0\n",
    "    dataset_score[\"summary_scores\"][\"cm_iou\"] = np.mean(dataset_score[\"summary_scores\"][\"cm_iou\"]) if len(dataset_score[\"summary_scores\"][\"cm_iou\"]) > 0 else 0.0 \n",
    "    dataset_score[\"summary_scores\"][\"cm_pred_iou\"] = np.mean(dataset_score[\"summary_scores\"][\"cm_pred_iou\"]) if len(dataset_score[\"summary_scores\"][\"cm_pred_iou\"]) > 0 else 0.0\n",
    "    \n",
    "    for category_id, score in per_category_score_dict.items():\n",
    "        print(f\"category_name: {score['category_name']}\")\n",
    "        print(f\"Category ID: {category_id}, Precision: {score['precision']:.4f}, Recall: {score['recall']:.4f}, F1 Score: {score['f1_score']:.4f}, cmIoU: {score['cm_iou']:.4f}, cmPredIoU: {score['cm_pred_iou']:.4f}, TP: {score['tp_num']}, FP: {score['fp_num']}, FN: {score['fn_num']}\")\n",
    "\n",
    "    for key,score in dataset_score[\"summary_scores\"].items():\n",
    "        print(f\"{key}: {score:.4f}\")\n",
    "        \n",
    "    for key,num in dataset_score[\"summary_data_num\"].items():\n",
    "        print(f\"{key}: {num}\")\n",
    "    return per_category_score_dict, dataset_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f826fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_json_path = \"/data_ssd/PASCAL-VOC/val_pascal-voc-one-class_for-kosmos2_one_class_with_delim.json\"\n",
    "correct_data = load_json(correct_json_path)\n",
    "\n",
    "generated_json_path = \"/data_ssd/PASCAL-VOC/val_pascal-voc-one-class_for-kosmos2_one_class_with_delim.json\"\n",
    "#generated_json_path = \"/home/omote/omote-data-ssd/iam-llms-finetune/experiment_output/kosmos-2_pascalvoc-one-class/with-delim_train-vision-proj-llm_cross-entropy_2025-07-14T16_51_39/checkpoint-6144/eval_output/val_pascal-voc-one-class_for-kosmos2_one_class_with_delim/max_new_tokens=512-temperature=1.0-top_p=1.0-top_k=50-num_beams=1-do_sample=False-/2025-07-14T19_28_38/eval_output.json\"\n",
    "#generated_json_path = \"/home/omote/omote-data-ssd/iam-llms-finetune/experiment_output/kosmos-2_pascalvoc-one-class/without-delim_train-vision-proj-llm_cross-entropy_2025-07-15T08_16_57/checkpoint-6144/eval_output/val_pascal-voc-one-class_for-kosmos2_one_class_without_delim/max_new_tokens=512-temperature=1.0-top_p=1.0-top_k=50-num_beams=1-do_sample=False-/2025-07-15T10_14_11/eval_output.json\"\n",
    "generated_json_path = \"/home/omote/omote-data-ssd/iam-llms-finetune/experiment_output/kosmos-2_pascalvoc-one-class/without-delim-noline_include-input-tokens_train-vision-proj-llm_cross-entropy_2025-07-15T16_35_34/checkpoint-6144/eval_output/val_pascal-voc-one-class_for-kosmos2_one_class_without_delim_noline/max_new_tokens=512-temperature=1.0-top_p=1.0-top_k=50-num_beams=1-do_sample=False-/2025-07-15T18_32_42/eval_output.json\"\n",
    "generated_data = load_json(generated_json_path)\n",
    "\n",
    "assert len(correct_data) == len(generated_data), \"Length of correct and generated data does not match.\"\n",
    "\n",
    "correct_data = sort_list_of_dicts(correct_data, \"id\")\n",
    "generated_data = sort_list_of_dicts(generated_data, \"id\")\n",
    "\n",
    "for correct, generated in zip(correct_data, generated_data):\n",
    "    assert correct[\"id\"] == generated[\"id\"], f\"ID mismatch: {correct['id']} != {generated['id']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f6814d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3618\n",
      "2510\n"
     ]
    }
   ],
   "source": [
    "ann_id_list = []\n",
    "for correct in correct_data:\n",
    "    ann_id_list.append(correct[\"ann_id\"])\n",
    "\n",
    "print(len(ann_id_list))\n",
    "print(len(set(ann_id_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "279f5c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pascal_voc_category():\n",
    "    cat_id2name = {\n",
    "    0: \"aeroplane\",\n",
    "    1: \"bicycle\",\n",
    "    2: \"bird\",\n",
    "    3: \"boat\",\n",
    "    4: \"bottle\",\n",
    "    5: \"bus\",\n",
    "    6: \"car\",\n",
    "    7: \"cat\",\n",
    "    8: \"chair\",\n",
    "    9: \"cow\",\n",
    "    10: \"diningtable\",\n",
    "    11: \"dog\",\n",
    "    12: \"horse\",\n",
    "    13: \"motorbike\",\n",
    "    14: \"person\",\n",
    "    15: \"pottedplant\",\n",
    "    16: \"sheep\",\n",
    "    17: \"sofa\",\n",
    "    18: \"train\",\n",
    "    19: \"tvmonitor\",\n",
    "    }\n",
    "    \n",
    "    cat_name2id = {v:k for k, v in cat_id2name.items()}\n",
    "    return cat_name2id, cat_id2name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37b0c54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name2id,category_id2name = get_pascal_voc_category()\n",
    "# category_name2id.update({\"unknown\": -1})\n",
    "# category_id2name.update({-1: \"unknown\"})\n",
    "processor = AutoProcessor.from_pretrained(\"/data_ssd/huggingface_model_weights/microsoft/kosmos-2-patch14-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e657d351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_annotations_for_coco(conversation_dataset,categories,processor,delete_region_failure=False,unknown_to_similar=False,sentence_transformer_model_path=None):\n",
    "    if unknown_to_similar and not delete_region_failure:\n",
    "        raise ValueError(\"unknown_to_similar is True but delete_region_failure is False. This combination is not supported.\")\n",
    "    elif unknown_to_similar and delete_region_failure:\n",
    "        get_most_similar_category = create_get_most_similar_category_func(\n",
    "            list(categories.keys()),\n",
    "            sentence_transformer_model_path\n",
    "        )\n",
    "    else:\n",
    "        get_most_similar_category = None\n",
    "\n",
    "    ann_id_converastaion_dict = {}\n",
    "    for i, conversation in enumerate(conversation_dataset):\n",
    "        if conversation[\"ann_id\"] not in ann_id_converastaion_dict:\n",
    "            ann_id_converastaion_dict[conversation[\"ann_id\"]] = []\n",
    "        ann_id_converastaion_dict[conversation[\"ann_id\"]].append(i)\n",
    "        \n",
    "    return_annotations = {}\n",
    "    \n",
    "    ann_keys_list = ann_id_converastaion_dict.keys()\n",
    "\n",
    "    region_failure_count = 0\n",
    "    region_failure_delim_count = 0\n",
    "    name_failure_count = 0\n",
    "    name_failure_delim_count = 0\n",
    "    name_match_count = 0\n",
    "    name_match_delim_count = 0\n",
    "\n",
    "    id_index = 0\n",
    "    for i, ann_key in enumerate(tqdm(ann_keys_list)):\n",
    "        for conversation in ann_id_converastaion_dict[ann_key]:\n",
    "            text = \"\"\n",
    "            for conv in conversation_dataset[conversation][\"conversations\"]:\n",
    "                text += conv[\"value\"]\n",
    "\n",
    "            caption, entities = processor.post_process_generation(text)\n",
    "            for name,_,bbox_list in entities:\n",
    "                if \"<patch_index\" in name and delete_region_failure:\n",
    "                    #raise ValueError(f\"Unexpected patch index in name: {name}\")\n",
    "                    region_failure_count += 1\n",
    "                    region_failure_delim_count += len(bbox_list)\n",
    "                    continue\n",
    "                elif name not in categories.keys():    \n",
    "                    name_failure_count += 1\n",
    "                    name_failure_delim_count += len(bbox_list)\n",
    "                    if get_most_similar_category is not None:\n",
    "                        name, score, _ = get_most_similar_category(name)\n",
    "                else:\n",
    "                    name_match_count += 1\n",
    "                    name_match_delim_count += len(bbox_list)\n",
    "                    \n",
    "                for bbox in bbox_list:\n",
    "                    annotation = {\n",
    "                        \"id\": id_index,\n",
    "                        \"image_id\": i ,\n",
    "                        \"category_id\": categories[name] if name in categories else categories[\"unknown\"],\n",
    "                        \"bbox\": [bbox[0], bbox[1], bbox[2] - bbox[0], bbox[3] - bbox[1]],  # [x, y, width, height]\n",
    "                        \"area\": (bbox[2] - bbox[0]) * (bbox[3] - bbox[1]),\n",
    "                        \"iscrowd\": 0,\n",
    "                        \"score\": 1.0,  # Assuming all annotations are perfect for dummy data\n",
    "                        \"category_name\": name,\n",
    "                        \"bbox_xyxy\": bbox,  # [x1, y1, x2, y2]\n",
    "                        \"is_unknown\": 1 if name not in categories else 0\n",
    "                    }\n",
    "                    \n",
    "                    if i not in return_annotations:\n",
    "                        return_annotations[i] = []\n",
    "                    return_annotations[i].append(annotation)\n",
    "                    id_index += 1\n",
    "\n",
    "    return_num_dict = {\n",
    "        \"region_failure_count\": region_failure_count,\n",
    "        \"region_failure_delim_count\": region_failure_delim_count,\n",
    "        \"name_failure_count\": name_failure_count,\n",
    "        \"name_failure_delim_count\": name_failure_delim_count,\n",
    "        \"name_match_count\": name_match_count,\n",
    "        \"name_match_delim_count\": name_match_delim_count\n",
    "    }\n",
    "    return return_annotations, return_num_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b03b2380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2510/2510 [00:00<00:00, 4723.14it/s]\n",
      "100%|██████████| 2510/2510 [00:07<00:00, 330.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2510\n",
      "2510\n",
      "GT region_failure_count: 0\n",
      "GT region_failure_delim_count: 0\n",
      "GT name_failure_count: 0\n",
      "GT name_failure_delim_count: 0\n",
      "GT name_match_count: 6307\n",
      "GT name_match_delim_count: 6307\n",
      "Generated region_failure_count: 248\n",
      "Generated region_failure_delim_count: 248\n",
      "Generated name_failure_count: 1243\n",
      "Generated name_failure_delim_count: 1243\n",
      "Generated name_match_count: 3625\n",
      "Generated name_match_delim_count: 3625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_gt_annotations, all_gt_num_dict = create_annotations_for_coco(correct_data, category_name2id, processor)\n",
    "all_pred_annotations, all_pred_num_dict = create_annotations_for_coco(generated_data, category_name2id, processor,\n",
    "            delete_region_failure=True, unknown_to_similar=True, sentence_transformer_model_path=\"/data_ssd/huggingface_model_weights/sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "print(len(all_gt_annotations))\n",
    "print(len(all_pred_annotations))\n",
    "for key, value in all_gt_num_dict.items():\n",
    "    print(f\"GT {key}: {value}\")\n",
    "for key, value in all_pred_num_dict.items():\n",
    "    print(f\"Generated {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4b023d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for anno in all_generated_annotations.values():\n",
    "#     for a in anno:\n",
    "#         if a[\"is_unknown\"] == 1:\n",
    "#             print(a[\"category_name\"])\n",
    "#             print(a[\"bbox_xyxy\"])\n",
    "#             print(a[\"bbox\"])\n",
    "#             print(a[\"bbox_xyxy\"][2] - a[\"bbox_xyxy\"][0])\n",
    "#             print(a[\"bbox_xyxy\"][3] - a[\"bbox_xyxy\"][1])\n",
    "#             print(\"-\" * 50)\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "23cfcd7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2510/2510 [00:01<00:00, 1278.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category_name: aeroplane\n",
      "Category ID: 0, Precision: 0.9007, Recall: 0.8194, F1 Score: 0.8581, cmIoU: 0.7671, cmPredIoU: 0.8554, TP: 127, FP: 14, FN: 28\n",
      "category_name: bicycle\n",
      "Category ID: 1, Precision: 0.8294, Recall: 0.7966, F1 Score: 0.8127, cmIoU: 0.7097, cmPredIoU: 0.8052, TP: 141, FP: 29, FN: 36\n",
      "category_name: bird\n",
      "Category ID: 2, Precision: 0.8325, Recall: 0.6749, F1 Score: 0.7455, cmIoU: 0.6082, cmPredIoU: 0.7946, TP: 164, FP: 33, FN: 79\n",
      "category_name: boat\n",
      "Category ID: 3, Precision: 0.7955, Recall: 0.7000, F1 Score: 0.7447, cmIoU: 0.6359, cmPredIoU: 0.7692, TP: 105, FP: 27, FN: 45\n",
      "category_name: bottle\n",
      "Category ID: 4, Precision: 0.5259, Recall: 0.2817, F1 Score: 0.3669, cmIoU: 0.2545, cmPredIoU: 0.5214, TP: 71, FP: 64, FN: 181\n",
      "category_name: bus\n",
      "Category ID: 5, Precision: 0.8922, Recall: 0.7982, F1 Score: 0.8426, cmIoU: 0.7444, cmPredIoU: 0.8748, TP: 91, FP: 11, FN: 23\n",
      "category_name: car\n",
      "Category ID: 6, Precision: 0.7864, Recall: 0.6128, F1 Score: 0.6888, cmIoU: 0.5574, cmPredIoU: 0.7918, TP: 383, FP: 104, FN: 242\n",
      "category_name: cat\n",
      "Category ID: 7, Precision: 0.8708, Recall: 0.9579, F1 Score: 0.9123, cmIoU: 0.8999, cmPredIoU: 0.9095, TP: 182, FP: 27, FN: 8\n",
      "category_name: chair\n",
      "Category ID: 8, Precision: 0.6923, Recall: 0.5201, F1 Score: 0.5940, cmIoU: 0.4626, cmPredIoU: 0.6622, TP: 207, FP: 92, FN: 191\n",
      "category_name: cow\n",
      "Category ID: 9, Precision: 0.8020, Recall: 0.6585, F1 Score: 0.7232, cmIoU: 0.6188, cmPredIoU: 0.8012, TP: 81, FP: 20, FN: 42\n",
      "category_name: diningtable\n",
      "Category ID: 10, Precision: 0.7227, Recall: 0.7679, F1 Score: 0.7446, cmIoU: 0.7103, cmPredIoU: 0.7577, TP: 86, FP: 33, FN: 26\n",
      "category_name: dog\n",
      "Category ID: 11, Precision: 0.9077, Recall: 0.9183, F1 Score: 0.9130, cmIoU: 0.8492, cmPredIoU: 0.8908, TP: 236, FP: 24, FN: 21\n",
      "category_name: horse\n",
      "Category ID: 12, Precision: 0.8865, Recall: 0.9111, F1 Score: 0.8986, cmIoU: 0.8199, cmPredIoU: 0.8434, TP: 164, FP: 21, FN: 16\n",
      "category_name: motorbike\n",
      "Category ID: 13, Precision: 0.8710, Recall: 0.7849, F1 Score: 0.8257, cmIoU: 0.7323, cmPredIoU: 0.8287, TP: 135, FP: 20, FN: 37\n",
      "category_name: person\n",
      "Category ID: 14, Precision: 0.8573, Recall: 0.5463, F1 Score: 0.6674, cmIoU: 0.4914, cmPredIoU: 0.7886, TP: 1274, FP: 212, FN: 1058\n",
      "category_name: pottedplant\n",
      "Category ID: 15, Precision: 0.6250, Recall: 0.3947, F1 Score: 0.4839, cmIoU: 0.3620, cmPredIoU: 0.6019, TP: 105, FP: 63, FN: 161\n",
      "category_name: sheep\n",
      "Category ID: 16, Precision: 0.8293, Recall: 0.5354, F1 Score: 0.6507, cmIoU: 0.4804, cmPredIoU: 0.7723, TP: 68, FP: 14, FN: 59\n",
      "category_name: sofa\n",
      "Category ID: 17, Precision: 0.8473, Recall: 0.8952, F1 Score: 0.8706, cmIoU: 0.8360, cmPredIoU: 0.8639, TP: 111, FP: 20, FN: 13\n",
      "category_name: train\n",
      "Category ID: 18, Precision: 0.9161, Recall: 0.9342, F1 Score: 0.9251, cmIoU: 0.8378, cmPredIoU: 0.8783, TP: 142, FP: 13, FN: 10\n",
      "category_name: tvmonitor\n",
      "Category ID: 19, Precision: 0.8117, Recall: 0.7911, F1 Score: 0.8013, cmIoU: 0.6819, cmPredIoU: 0.7329, TP: 125, FP: 29, FN: 33\n",
      "micro_precision: 0.8213\n",
      "micro_recall: 0.6339\n",
      "micro_f1: 0.7155\n",
      "m_iou: 0.5755\n",
      "m_pred_iou: 0.7878\n",
      "oc_cost: 0.1183\n",
      "macro_precision: 0.8101\n",
      "macro_recall: 0.7150\n",
      "macro_f1: 0.7535\n",
      "cm_iou: 0.6530\n",
      "cm_pred_iou: 0.7872\n",
      "tp_num: 3998\n",
      "fp_num: 870\n",
      "fn_num: 2309\n",
      "unkonown_fp_num: 0\n",
      "iou_num: 6307\n",
      "pred_iou_num: 4607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "per_image_result_dict, oc_cost_list = get_per_image_class_result_and_oc_cost(all_gt_annotations, all_pred_annotations, category_name2id, iou_threshold=0.5)\n",
    "per_category_result_dict = convert_per_class_result_dict(per_image_result_dict)\n",
    "\n",
    "_,output_data = calculate_score(per_category_result_dict, oc_cost_list,category_id2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659a5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496a0a14",
   "metadata": {},
   "source": [
    "# without-delim-noline\n",
    "# with unknown no sim\n",
    "micro_precision: 0.6588\n",
    "micro_recall: 0.5085\n",
    "micro_f1: 0.5740\n",
    "m_iou: 0.4632\n",
    "m_pred_iou: 0.8062\n",
    "oc_cost: 0.1699\n",
    "macro_precision: 0.8736\n",
    "macro_recall: 0.6151\n",
    "macro_f1: 0.7101\n",
    "cm_iou: 0.5638\n",
    "cm_pred_iou: 0.8007\n",
    "tp_num: 3207\n",
    "fp_num: 1661\n",
    "fn_num: 3100\n",
    "unkonown_fp_num: 1243\n",
    "iou_num: 6307\n",
    "pred_iou_num: 3624\n",
    "\n",
    "# with unknown with sim\n",
    "micro_precision: 0.8209\n",
    "micro_recall: 0.6336\n",
    "micro_f1: 0.7152\n",
    "m_iou: 0.5752\n",
    "m_pred_iou: 0.7878\n",
    "oc_cost: 0.1183\n",
    "macro_precision: 0.8111\n",
    "macro_recall: 0.7149\n",
    "macro_f1: 0.7539\n",
    "cm_iou: 0.6529\n",
    "cm_pred_iou: 0.7872\n",
    "tp_num: 3996\n",
    "fp_num: 872\n",
    "fn_num: 2311\n",
    "unkonown_fp_num: 9\n",
    "iou_num: 6307\n",
    "pred_iou_num: 4605\n",
    "\n",
    "# no unknown with sim\n",
    "micro_precision: 0.8213\n",
    "micro_recall: 0.6339\n",
    "micro_f1: 0.7155\n",
    "m_iou: 0.5755\n",
    "m_pred_iou: 0.7878\n",
    "oc_cost: 0.1183\n",
    "macro_precision: 0.8101\n",
    "macro_recall: 0.7150\n",
    "macro_f1: 0.7535\n",
    "cm_iou: 0.6530\n",
    "cm_pred_iou: 0.7872\n",
    "tp_num: 3998\n",
    "fp_num: 870\n",
    "fn_num: 2309\n",
    "unkonown_fp_num: 0\n",
    "iou_num: 6307\n",
    "pred_iou_num: 4607"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257218c",
   "metadata": {},
   "source": [
    "# with-delim\n",
    "# with unkonown no sim\n",
    "micro_precision: 0.7827\n",
    "micro_recall: 0.7810\n",
    "micro_f1: 0.7818\n",
    "m_iou: 0.7047\n",
    "m_pred_iou: 0.7666\n",
    "oc_cost: 0.0840\n",
    "macro_precision: 0.7953\n",
    "macro_recall: 0.8050\n",
    "macro_f1: 0.7989\n",
    "cm_iou: 0.7296\n",
    "cm_pred_iou: 0.7780\n",
    "tp_num: 4926\n",
    "fp_num: 1368\n",
    "fn_num: 1381\n",
    "unkonown_fp_num: 5\n",
    "iou_num: 6307\n",
    "pred_iou_num: 5798\n",
    "\n",
    "# with unkonown with sim\n",
    "micro_precision: 0.7827\n",
    "micro_recall: 0.7810\n",
    "micro_f1: 0.7818\n",
    "m_iou: 0.7047\n",
    "m_pred_iou: 0.7666\n",
    "oc_cost: 0.0840\n",
    "macro_precision: 0.7953\n",
    "macro_recall: 0.8050\n",
    "macro_f1: 0.7989\n",
    "cm_iou: 0.7296\n",
    "cm_pred_iou: 0.7780\n",
    "tp_num: 4926\n",
    "fp_num: 1368\n",
    "fn_num: 1381\n",
    "unkonown_fp_num: 5\n",
    "iou_num: 6307\n",
    "pred_iou_num: 5798\n",
    "\n",
    "# no unknown with sim\n",
    "micro_precision: 0.7827\n",
    "micro_recall: 0.7810\n",
    "micro_f1: 0.7818\n",
    "m_iou: 0.7047\n",
    "m_pred_iou: 0.7666\n",
    "oc_cost: 0.0840\n",
    "macro_precision: 0.7947\n",
    "macro_recall: 0.8050\n",
    "macro_f1: 0.7986\n",
    "cm_iou: 0.7296\n",
    "cm_pred_iou: 0.7780\n",
    "tp_num: 4926\n",
    "fp_num: 1368\n",
    "fn_num: 1381\n",
    "unkonown_fp_num: 0\n",
    "iou_num: 6307\n",
    "pred_iou_num: 5798"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e88580",
   "metadata": {},
   "source": [
    "\n",
    "# without-delim\n",
    "# with unknown no sim\n",
    "micro_precision: 0.6347\n",
    "micro_recall: 0.5245\n",
    "micro_f1: 0.5744\n",
    "m_iou: 0.4754\n",
    "m_pred_iou: 0.8018\n",
    "oc_cost: 0.1633\n",
    "macro_precision: 0.8586\n",
    "macro_recall: 0.6327\n",
    "macro_f1: 0.7169\n",
    "cm_iou: 0.5760\n",
    "cm_pred_iou: 0.7994\n",
    "tp_num: 3308\n",
    "fp_num: 1904\n",
    "fn_num: 2999\n",
    "unkonown_fp_num: 1383\n",
    "iou_num: 6307\n",
    "pred_iou_num: 3740\n",
    "\n",
    "# with unknown with sim\n",
    "micro_precision: 0.7972\n",
    "micro_recall: 0.6588\n",
    "micro_f1: 0.7214\n",
    "m_iou: 0.5945\n",
    "m_pred_iou: 0.7867\n",
    "oc_cost: 0.1114\n",
    "macro_precision: 0.8043\n",
    "macro_recall: 0.7183\n",
    "macro_f1: 0.7532\n",
    "cm_iou: 0.6519\n",
    "cm_pred_iou: 0.7889\n",
    "tp_num: 4155\n",
    "fp_num: 1057\n",
    "fn_num: 2152\n",
    "unkonown_fp_num: 84\n",
    "iou_num: 6307\n",
    "pred_iou_num: 4766\n",
    "\n",
    "\n",
    "# no unknown with sim\n",
    "micro_precision: 0.7972\n",
    "micro_recall: 0.6588\n",
    "micro_f1: 0.7214\n",
    "m_iou: 0.5945\n",
    "m_pred_iou: 0.7864\n",
    "oc_cost: 0.1114\n",
    "macro_precision: 0.7942\n",
    "macro_recall: 0.7183\n",
    "macro_f1: 0.7486\n",
    "cm_iou: 0.6519\n",
    "cm_pred_iou: 0.7889\n",
    "tp_num: 4155\n",
    "fp_num: 1057\n",
    "fn_num: 2152\n",
    "unkonown_fp_num: 0\n",
    "iou_num: 6307\n",
    "pred_iou_num: 4768\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
